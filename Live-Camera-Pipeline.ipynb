{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importin Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MediaPipe Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hand = list(range(21))\n",
    "\n",
    "filtered_pose = [11, 12, 13, 14, 15, 16]\n",
    "\n",
    "filtered_face = [0, 4, 7, 8, 10, 13, 14, 17, 21, 33, 37, 39, 40, 46, 52, 53, 54, 55, 58,\n",
    "                 61, 63, 65, 66, 67, 70, 78, 80, 81, 82, 84, 87, 88, 91, 93, 95, 103, 105,\n",
    "                 107, 109, 127, 132, 133, 136, 144, 145, 146, 148, 149, 150, 152, 153, 154,\n",
    "                 155, 157, 158, 159, 160, 161, 162, 163, 172, 173, 176, 178, 181, 185, 191,\n",
    "                 234, 246, 249, 251, 263, 267, 269, 270, 276, 282, 283, 284, 285, 288, 291,\n",
    "                 293, 295, 296, 297, 300, 308, 310, 311, 312, 314, 317, 318, 321, 323, 324,\n",
    "                 332, 334, 336, 338, 356, 361, 362, 365, 373, 374, 375, 377, 378, 379, 380,\n",
    "                 381, 382, 384, 385, 386, 387, 388, 389, 390, 397, 398, 400, 402, 405, 409,\n",
    "                 415, 454, 466, 468, 473]\n",
    "\n",
    "HAND_NUM = len(filtered_hand)\n",
    "POSE_NUM = len(filtered_pose)\n",
    "FACE_NUM = len(filtered_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mp.solutions.hands.Hands()\n",
    "pose = mp.solutions.pose.Pose()\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "\n",
    "def get_frame_landmarks(frame):\n",
    "    \n",
    "    all_landmarks = np.zeros((HAND_NUM * 2 + POSE_NUM + FACE_NUM, 3))\n",
    "    \n",
    "    def get_hands(frame):\n",
    "        results_hands = hands.process(frame)\n",
    "        if results_hands.multi_hand_landmarks:\n",
    "            for i, hand_landmarks in enumerate(results_hands.multi_hand_landmarks):\n",
    "                if results_hands.multi_handedness[i].classification[0].index == 0: \n",
    "                    all_landmarks[:HAND_NUM, :] = np.array(\n",
    "                        [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]) # right\n",
    "                else:\n",
    "                    all_landmarks[HAND_NUM:HAND_NUM * 2, :] = np.array(\n",
    "                        [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]) # left\n",
    "\n",
    "    def get_pose(frame):\n",
    "        results_pose = pose.process(frame)\n",
    "        if results_pose.pose_landmarks:\n",
    "            all_landmarks[HAND_NUM * 2:HAND_NUM * 2 + POSE_NUM, :] = np.array(\n",
    "                [(lm.x, lm.y, lm.z) for lm in results_pose.pose_landmarks.landmark])[filtered_pose]\n",
    "        \n",
    "    def get_face(frame):\n",
    "        results_face = face_mesh.process(frame)\n",
    "        if results_face.multi_face_landmarks:\n",
    "            all_landmarks[HAND_NUM * 2 + POSE_NUM:, :] = np.array(\n",
    "                [(lm.x, lm.y, lm.z) for lm in results_face.multi_face_landmarks[0].landmark])[filtered_face]\n",
    "        \n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        executor.submit(get_hands, frame)\n",
    "        executor.submit(get_pose, frame)\n",
    "        executor.submit(get_face, frame)\n",
    "\n",
    "    return all_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:\\\\Users\\\\dell\\\\Desktop\\AI\\\\Grad\\\\2nd\\\\Testing Model\\\\test.h5\"\n",
    "index_mapping_path = \"C:\\\\Users\\\\dell\\\\Desktop\\\\AI\\\\Grad\\\\2nd\\\\Testing Model\\\\index_mapping_586.json\"\n",
    "label_mapping_path = \"C:\\\\Users\\\\dell\\\\Desktop\\\\AI\\\\Grad\\\\2nd\\\\Testing Model\\\\label_mapping_586.json\"\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "index_mapping = json.load(open(index_mapping_path, \"r\"))\n",
    "label_mapping = json.load(open(label_mapping_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 100, 180, 3), (None, 586))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape, model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "go back and forth\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "go back and forth\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "firetruck\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "swear in\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "make believe\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "take off\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "river\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "know nothing\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "greet\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "know nothing\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "sequence = deque(maxlen=model.input_shape[1])\n",
    "for _ in range(model.input_shape[1]):\n",
    "    sequence.append(np.zeros((model.input_shape[2], 3)))\n",
    "\n",
    "tic = tac = 0\n",
    "counter = 0\n",
    "step = model.input_shape[1]\n",
    "label = ''\n",
    "   \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: continue\n",
    "    \n",
    "    tac = time.time()\n",
    "    fps = str(int(1 / (tac - tic)))\n",
    "    tic = tac\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_rgb.flags.writeable = False\n",
    "    frame_landmarks = get_frame_landmarks(frame_rgb)\n",
    "    \n",
    "    for point in frame_landmarks:\n",
    "        x = int(point[0] * width)\n",
    "        y = int(point[1] * height)\n",
    "        cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "    cv2.putText(frame, fps, (30,60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, label, (30, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    sequence.append(frame_landmarks)\n",
    "    counter = (counter + 1) % step\n",
    "    if counter == 0:     \n",
    "        sequence_array = np.array(sequence)\n",
    "        sequence_array = sequence_array.reshape(1, model.input_shape[1], model.input_shape[2], 3)\n",
    "        \n",
    "        prediction = model.predict(sequence_array)\n",
    "        prediction = prediction.reshape(-1)\n",
    "        prediction = prediction.argmax()\n",
    "        \n",
    "        label = index_mapping[str(prediction)]\n",
    "        print(label)\n",
    "    \n",
    "    cv2.imshow(\"Test\", frame)\n",
    "    cv2.setWindowProperty(\"Test\", cv2.WND_PROP_TOPMOST, 1)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "no big deal\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "go back and forth\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "basketball\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "cellphone\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "go back and forth\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "motorcycle\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "sequence = deque(maxlen=model.input_shape[1])\n",
    "for _ in range(model.input_shape[1]):\n",
    "    sequence.append(np.zeros((model.input_shape[2], 3)))\n",
    "\n",
    "tic = tac = 0\n",
    "counter = 0\n",
    "step = model.input_shape[1]\n",
    "label = ''\n",
    "\n",
    "\n",
    "output_fps = 1/4 \n",
    "output_width = width\n",
    "output_height = height\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter('output.avi', fourcc, output_fps, (output_width, output_height))\n",
    "\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    \n",
    "    tac = time.time()\n",
    "    fps = str(int(1 / (tac - tic)))\n",
    "    tic = tac\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_rgb.flags.writeable = False\n",
    "    frame_landmarks = get_frame_landmarks(frame_rgb)\n",
    "    \n",
    "    for point in frame_landmarks:\n",
    "        x = int(point[0] * width)\n",
    "        y = int(point[1] * height)\n",
    "        cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "    cv2.putText(frame, fps, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, label, (30, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    sequence.append(frame_landmarks)\n",
    "    counter = (counter + 1) % step\n",
    "    if counter == 0:\n",
    "        sequence_array = np.array(sequence)\n",
    "        sequence_array = sequence_array.reshape(1, model.input_shape[1], model.input_shape[2], 3)\n",
    "        \n",
    "        prediction = model.predict(sequence_array)\n",
    "        prediction = prediction.reshape(-1)\n",
    "        prediction = prediction.argmax()\n",
    "        \n",
    "        label = index_mapping[str(prediction)]\n",
    "        print(label)\n",
    "    \n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    cv2.putText(frame, f\"Time: {elapsed_time:.2f}s\", (30, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    if elapsed_time >= 4:\n",
    "        output.write(frame)  \n",
    "        start_time = current_time\n",
    "    \n",
    "    cv2.imshow(\"Test\", frame)\n",
    "    cv2.setWindowProperty(\"Test\", cv2.WND_PROP_TOPMOST, 1)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "output.release()  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
