{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7219693,"sourceType":"datasetVersion","datasetId":4178608},{"sourceId":7345299,"sourceType":"datasetVersion","datasetId":4265176},{"sourceId":7591625,"sourceType":"datasetVersion","datasetId":4268834}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abd0kamel/mutemotion-asl-citizen-translation-model?scriptVersionId=162320939\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div id=\"Introduction\">\n    \n# **Introduction**\n\n<h3> This notebook aims to use MediaPipe landmarks detection as the starting point\n    \n<h3> for building an American Sign Language Translation Model using <b>ASL Citizen</b> Dataset\n            \n**<h3> Sections:**\n* [Importing Libraries](#Importing_Libraries)\n* [Data Preparation](#Data_Preparation)\n* [MediaPipe Implementation](#MediaPipe_Implementation)\n* [Visualizing Landmarks](#Visualizing_Landmarks)\n* [Data Encoding](#Data_Encoding)\n* [Label Filtering](#Label_Filtering)\n* [Data Loading](#Data_Loading) --> (Training Start Here)\n* [Data Augmentation](#Data_Augmentation)\n* [Data Preprocessing](#Data_Preprocessing)\n* [Label Encoding](#Label_Encoding)\n* [Model Training](#Model_Training)\n* [Transformer Experiment](#Transformer_Experiment)\n* [Model Visualization](#Model_Visualization)\n* [Extras](#Extras)","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Importing_Libraries\">\n    \n# **Importing Libraries**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install -q mediapipe==0.10.7","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport json\nimport time\nimport shutil\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n# import mediapipe as mp\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom concurrent.futures import ThreadPoolExecutor\nfrom IPython.display import clear_output, FileLink","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:49:25.247178Z","iopub.execute_input":"2024-02-09T13:49:25.247529Z","iopub.status.idle":"2024-02-09T13:49:38.021234Z","shell.execute_reply.started":"2024-02-09T13:49:25.247502Z","shell.execute_reply":"2024-02-09T13:49:38.020299Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-09 13:49:27.722486: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-09 13:49:27.722620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-09 13:49:27.863380: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Data_Preparation\">\n    \n# **Data Preparation**\n**<h2>(Done Once)**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/input/asl-citizen/ASL_Citizen/splits/train.csv'\nval_path = '/kaggle/input/asl-citizen/ASL_Citizen/splits/val.csv'\ntest_path = '/kaggle/input/asl-citizen/ASL_Citizen/splits/test.csv'\n\ntrain_data = pd.read_csv(train_path)\nval_data = pd.read_csv(val_path)\ntest_data = pd.read_csv(test_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:33:30.394566Z","iopub.execute_input":"2024-01-26T18:33:30.395228Z","iopub.status.idle":"2024-01-26T18:33:30.599375Z","shell.execute_reply.started":"2024-01-26T18:33:30.395166Z","shell.execute_reply":"2024-01-26T18:33:30.598487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['split'] = 'train'\nval_data['split'] = 'val'\ntest_data['split'] = 'test'\n\ntrain_data = train_data[['Video file', 'Gloss', 'split']]\nval_data = val_data[['Video file', 'Gloss', 'split']]\ntest_data = test_data[['Video file', 'Gloss', 'split']]\n\ndata = pd.concat([train_data, val_data, test_data], ignore_index=True)\ndata = data.sample(frac=1, random_state=42, ignore_index=True)\ndata = data.rename(columns={'Gloss':'label', 'Video file': 'video'})\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:33:37.884103Z","iopub.execute_input":"2024-01-26T18:33:37.884439Z","iopub.status.idle":"2024-01-26T18:33:37.945793Z","shell.execute_reply.started":"2024-01-26T18:33:37.884412Z","shell.execute_reply":"2024-01-26T18:33:37.944905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_label(file_name):\n    label_parts = file_name.split(\"-\")[1].split(\".\")[0].replace(\"_\", \" \").split(\" \")\n    label_parts = [part for part in label_parts if part != '']\n    if label_parts[0].startswith('seed'):\n        label_parts[0] = label_parts[0][4:]\n    if label_parts[-1].isdigit():\n        label_parts = label_parts[:-1]\n    label_parts = [part.lower() for part in label_parts]\n    return ' '.join(label_parts)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:33:42.238531Z","iopub.execute_input":"2024-01-26T18:33:42.238909Z","iopub.status.idle":"2024-01-26T18:33:42.245464Z","shell.execute_reply.started":"2024-01-26T18:33:42.238882Z","shell.execute_reply":"2024-01-26T18:33:42.244024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.insert(data.columns.get_loc('label') + 1, 'clean label', data['video'].apply(extract_label))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:33:42.481245Z","iopub.execute_input":"2024-01-26T18:33:42.481561Z","iopub.status.idle":"2024-01-26T18:33:42.656142Z","shell.execute_reply.started":"2024-01-26T18:33:42.481537Z","shell.execute_reply":"2024-01-26T18:33:42.654929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['clean label'] == '']","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:33:45.600231Z","iopub.execute_input":"2024-01-26T18:33:45.600834Z","iopub.status.idle":"2024-01-26T18:33:45.615794Z","shell.execute_reply.started":"2024-01-26T18:33:45.600803Z","shell.execute_reply":"2024-01-26T18:33:45.614885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.iloc[59741, data.columns.get_loc('clean label')] = 'sour'\ndata[data['clean label'] == '']","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:33:49.24355Z","iopub.execute_input":"2024-01-26T18:33:49.243923Z","iopub.status.idle":"2024-01-26T18:33:49.258387Z","shell.execute_reply.started":"2024-01-26T18:33:49.243893Z","shell.execute_reply":"2024-01-26T18:33:49.257499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv(\"data.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T21:16:00.314598Z","iopub.execute_input":"2023-12-28T21:16:00.315117Z","iopub.status.idle":"2023-12-28T21:16:00.746812Z","shell.execute_reply.started":"2023-12-28T21:16:00.31504Z","shell.execute_reply":"2023-12-28T21:16:00.745169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"MediaPipe_Implementation\">\n\n# **MediaPipe Implementation**\n**<h2>(Not important when training)**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"filtered_hand = list(range(21))\n\nfiltered_pose = [11, 12, 13, 14, 15, 16]\n\nfiltered_face = [0, 4, 7, 8, 10, 13, 14, 17, 21, 33, 37, 39, 40, 46, 52, 53, 54, 55, 58,\n                 61, 63, 65, 66, 67, 70, 78, 80, 81, 82, 84, 87, 88, 91, 93, 95, 103, 105,\n                 107, 109, 127, 132, 133, 136, 144, 145, 146, 148, 149, 150, 152, 153, 154,\n                 155, 157, 158, 159, 160, 161, 162, 163, 172, 173, 176, 178, 181, 185, 191,\n                 234, 246, 249, 251, 263, 267, 269, 270, 276, 282, 283, 284, 285, 288, 291,\n                 293, 295, 296, 297, 300, 308, 310, 311, 312, 314, 317, 318, 321, 323, 324,\n                 332, 334, 336, 338, 356, 361, 362, 365, 373, 374, 375, 377, 378, 379, 380,\n                 381, 382, 384, 385, 386, 387, 388, 389, 390, 397, 398, 400, 402, 405, 409,\n                 415, 454, 466, 468, 473]\n\nHAND_NUM = len(filtered_hand)\nPOSE_NUM = len(filtered_pose)\nFACE_NUM = len(filtered_face)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:34:11.213805Z","iopub.execute_input":"2024-01-26T18:34:11.214132Z","iopub.status.idle":"2024-01-26T18:34:11.22314Z","shell.execute_reply.started":"2024-01-26T18:34:11.214107Z","shell.execute_reply":"2024-01-26T18:34:11.221432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hands = mp.solutions.hands.Hands()\npose = mp.solutions.pose.Pose()\nface_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n\ndef get_frame_landmarks(frame):\n    \n    all_landmarks = np.zeros((HAND_NUM * 2 + POSE_NUM + FACE_NUM, 3))\n    \n    def get_hands(frame):\n        results_hands = hands.process(frame)\n        if results_hands.multi_hand_landmarks:\n            for i, hand_landmarks in enumerate(results_hands.multi_hand_landmarks):\n                if results_hands.multi_handedness[i].classification[0].index == 0: \n                    all_landmarks[:HAND_NUM, :] = np.array(\n                        [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]) # right\n                else:\n                    all_landmarks[HAND_NUM:HAND_NUM * 2, :] = np.array(\n                        [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]) # left\n\n    def get_pose(frame):\n        results_pose = pose.process(frame)\n        if results_pose.pose_landmarks:\n            all_landmarks[HAND_NUM * 2:HAND_NUM * 2 + POSE_NUM, :] = np.array(\n                [(lm.x, lm.y, lm.z) for lm in results_pose.pose_landmarks.landmark])[filtered_pose]\n        \n    def get_face(frame):\n        results_face = face_mesh.process(frame)\n        if results_face.multi_face_landmarks:\n            all_landmarks[HAND_NUM * 2 + POSE_NUM:, :] = np.array(\n                [(lm.x, lm.y, lm.z) for lm in results_face.multi_face_landmarks[0].landmark])[filtered_face]\n        \n    with ThreadPoolExecutor(max_workers=3) as executor:\n        executor.submit(get_hands, frame)\n        executor.submit(get_pose, frame)\n        executor.submit(get_face, frame)\n\n    return all_landmarks","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:34:11.356383Z","iopub.execute_input":"2024-01-26T18:34:11.356736Z","iopub.status.idle":"2024-01-26T18:34:11.395394Z","shell.execute_reply.started":"2024-01-26T18:34:11.35671Z","shell.execute_reply":"2024-01-26T18:34:11.39469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_video_landmarks(video_path):\n    cap = cv2.VideoCapture(video_path)\n    all_frame_landmarks = []\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n            \n        frame.flags.writeable = False\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        frame_landmarks = get_frame_landmarks(frame)\n        all_frame_landmarks.append(frame_landmarks)\n\n    with ThreadPoolExecutor(max_workers=4) as executor:\n        executor.submit(cap.release)\n        executor.submit(hands.reset)\n        executor.submit(pose.reset)\n        executor.submit(face_mesh.reset)\n        \n    return np.array(all_frame_landmarks)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:34:12.69119Z","iopub.execute_input":"2024-01-26T18:34:12.691537Z","iopub.status.idle":"2024-01-26T18:34:12.697753Z","shell.execute_reply.started":"2024-01-26T18:34:12.69151Z","shell.execute_reply":"2024-01-26T18:34:12.696828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_landmarks(input_path, output_path, video_landmarks):\n    cap = cv2.VideoCapture(input_path)\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n        \n    frame_index = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frame_landmarks = video_landmarks[frame_index]\n        landmarks = [(int(x * width), int(y * height)) for x, y, _ in frame_landmarks]\n        for x, y in landmarks:\n            cv2.circle(frame, (x, y), 3, (0, 0, 255), -1)\n        out.write(frame)\n        frame_index += 1\n\n    cap.release()\n    out.release()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:34:14.209882Z","iopub.execute_input":"2024-01-26T18:34:14.21023Z","iopub.status.idle":"2024-01-26T18:34:14.216862Z","shell.execute_reply.started":"2024-01-26T18:34:14.2102Z","shell.execute_reply":"2024-01-26T18:34:14.2161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Visualizing_Landmarks\">\n\n# **Visualizing Landmarks**\n**<h2>(Not important when training)**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"import requests\nfrom PIL import Image\nfrom io import BytesIO\n\nimage_url = 'https://images.unsplash.com/photo-1515294898968-a408405d7674'\nresponse = requests.get(image_url)\nimg = Image.open(BytesIO(response.content))\nimg = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n\nplt.figure(figsize=(8, 8))\nplt.imshow(img[:,:,::-1])\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:34:15.642823Z","iopub.execute_input":"2024-01-26T18:34:15.64343Z","iopub.status.idle":"2024-01-26T18:34:18.498804Z","shell.execute_reply.started":"2024-01-26T18:34:15.643396Z","shell.execute_reply":"2024-01-26T18:34:18.497795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height, width, _ = img.shape\n\nframe_landmarks = get_frame_landmarks(img[:,:,::-1])\nfor landmark in frame_landmarks:\n    x = int(landmark[0] * width)\n    y = int(landmark[1] * height)\n    cv2.circle(img, (x, y), 10, (0, 255, 0), -1)\n\nplt.figure(figsize=(8, 8))\nplt.imshow(img[:,:,::-1])\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T18:34:18.500221Z","iopub.execute_input":"2024-01-26T18:34:18.501306Z","iopub.status.idle":"2024-01-26T18:34:21.192493Z","shell.execute_reply.started":"2024-01-26T18:34:18.501266Z","shell.execute_reply":"2024-01-26T18:34:21.191585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = data.iloc[75]\nvideo_dir = '/kaggle/input/asl-citizen/ASL_Citizen/videos'\ninput_path = os.path.join(video_dir, test['video'])\nvideo_landmarks = get_video_landmarks(input_path)\n\noutput_path = '/kaggle/working/landmarks_test.mp4'\ndraw_landmarks(input_path, output_path, video_landmarks)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T22:59:29.946864Z","iopub.execute_input":"2023-12-27T22:59:29.947199Z","iopub.status.idle":"2023-12-27T22:59:32.781581Z","shell.execute_reply.started":"2023-12-27T22:59:29.947173Z","shell.execute_reply":"2023-12-27T22:59:32.780676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Data_Encoding\">\n    \n# **Data Encoding**\n**<h2>(Done Once)**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"txt_path = '/kaggle/working/completed.txt'\nvideo_dir = '/kaggle/input/asl-citizen/ASL_Citizen/videos'\nnpy_dir = '/kaggle/working/landmarks'\nos.makedirs(npy_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T13:03:06.157408Z","iopub.execute_input":"2024-01-05T13:03:06.15813Z","iopub.status.idle":"2024-01-05T13:03:06.164485Z","shell.execute_reply.started":"2024-01-05T13:03:06.158093Z","shell.execute_reply":"2024-01-05T13:03:06.162932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = []\nwith open('/kaggle/working/Filtered Labels/filtered_labels_221.txt', 'r') as file:\n    labels = file.read().splitlines()\n    \nlen(labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T13:03:18.929853Z","iopub.execute_input":"2024-01-05T13:03:18.930931Z","iopub.status.idle":"2024-01-05T13:03:18.943715Z","shell.execute_reply.started":"2024-01-05T13:03:18.930857Z","shell.execute_reply":"2024-01-05T13:03:18.941792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/asl-citizen-encoded/Data/data.csv')\ndata = data[data['clean label'].isin(labels)].reset_index(drop=True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T13:03:22.420504Z","iopub.execute_input":"2024-01-05T13:03:22.420941Z","iopub.status.idle":"2024-01-05T13:03:22.552791Z","shell.execute_reply.started":"2024-01-05T13:03:22.420905Z","shell.execute_reply":"2024-01-05T13:03:22.551343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T13:03:25.156153Z","iopub.execute_input":"2024-01-05T13:03:25.156574Z","iopub.status.idle":"2024-01-05T13:03:25.164072Z","shell.execute_reply.started":"2024-01-05T13:03:25.156522Z","shell.execute_reply":"2024-01-05T13:03:25.162904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    completed_files = set()\n    if os.path.exists(txt_path):\n        with open(txt_path, 'r') as file:\n            completed_files = {line.strip() for line in file}\n            \n    for i in tqdm(range(len(data)), ncols=100):\n        video_name = data.iloc[i]['video'].split('.')[0]\n        if video_name in completed_files: continue\n        npy_path = os.path.join(npy_dir, f'{video_name}.npy')\n        video_path = os.path.join(video_dir, f'{video_name}.mp4')\n\n        try:\n            video_landmarks = get_video_landmarks(video_path)\n            np.save(npy_path, video_landmarks)\n            \n            with open(txt_path, 'a') as file:\n                file.write(f\"{video_name}\\n\")\n            completed_files.add(video_name)\n            \n        except Exception as e:\n            print(f\"\\nError encoding {i}: {video_path}\\n{e}\")\n            continue   \n        clear_output(wait=True)\n\nexcept KeyboardInterrupt:\n    print(\"\\nLoading process interrupted by user.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-05T13:49:00.44666Z","iopub.execute_input":"2024-01-05T13:49:00.447111Z","iopub.status.idle":"2024-01-05T13:49:00.740015Z","shell.execute_reply.started":"2024-01-05T13:49:00.447073Z","shell.execute_reply":"2024-01-05T13:49:00.739034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks_dict = {}\n\nfor filename in os.listdir(npy_dir):\n    if filename.endswith('.npy'):\n        key = os.path.splitext(filename)[0]\n        landmarks = np.load(os.path.join(npy_dir, filename), allow_pickle=True)\n        landmarks_dict[key] = landmarks\n\nnp.savez_compressed('/kaggle/working/landmarks.npz', **landmarks_dict)\n\nFileLink(r'landmarks.npz')","metadata":{"execution":{"iopub.status.busy":"2024-01-05T13:49:03.615878Z","iopub.execute_input":"2024-01-05T13:49:03.617495Z","iopub.status.idle":"2024-01-05T13:53:42.608613Z","shell.execute_reply.started":"2024-01-05T13:49:03.617418Z","shell.execute_reply":"2024-01-05T13:53:42.607217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shutil.rmtree(npy_dir)\n# os.remove('/kaggle/working/completed.txt')\n# os.remove('/kaggle/working/landmarks_test.mp4')","metadata":{"execution":{"iopub.status.busy":"2023-12-26T22:31:38.364181Z","iopub.execute_input":"2023-12-26T22:31:38.36552Z","iopub.status.idle":"2023-12-26T22:31:39.300509Z","shell.execute_reply.started":"2023-12-26T22:31:38.365483Z","shell.execute_reply":"2023-12-26T22:31:39.29967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Label_Filtering\">\n\n# **Label Filtering**\n**<h2>(Done Once)**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"import fasttext\nimport fasttext.util\n\nfasttext.util.download_model('en', if_exists='ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import fasttext\n\nft = fasttext.load_model('cc.en.300.bin')","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:47:27.94486Z","iopub.execute_input":"2024-01-06T22:47:27.946043Z","iopub.status.idle":"2024-01-06T22:47:37.415249Z","shell.execute_reply.started":"2024-01-06T22:47:27.946009Z","shell.execute_reply":"2024-01-06T22:47:37.414158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/asl-citizen-encoded/Data/data.csv')\nlabels = data['clean label'].unique().tolist()\nlen(data), len(labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:47:41.165744Z","iopub.execute_input":"2024-01-06T22:47:41.166245Z","iopub.status.idle":"2024-01-06T22:47:41.350389Z","shell.execute_reply.started":"2024-01-06T22:47:41.166204Z","shell.execute_reply":"2024-01-06T22:47:41.349457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_dir = '/kaggle/working/Vector Encoded Labels'\nos.makedirs(labels_dir, exist_ok=True)\n\nfor i in tqdm(range(len(labels)), ncols=100):\n    label_vector = ft.get_sentence_vector(labels[i])\n    label_path = os.path.join(labels_dir, f'{labels[i]}.npy')\n    np.save(label_path, label_vector)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:47:44.288202Z","iopub.execute_input":"2024-01-06T22:47:44.288597Z","iopub.status.idle":"2024-01-06T22:47:44.591971Z","shell.execute_reply.started":"2024-01-06T22:47:44.288567Z","shell.execute_reply":"2024-01-06T22:47:44.591074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_dir = '/kaggle/input/asl-citizen-encoded/Vector Encoded Labels'\nencoded_labels = {}\n\nfor filename in os.listdir(labels_dir):\n    if filename.endswith('.npy'):\n        label = os.path.splitext(filename)[0]\n        encoded_label = np.load(os.path.join(labels_dir, filename), allow_pickle=True)\n        encoded_labels[label] = encoded_label\n        \nlen(encoded_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:49:36.005287Z","iopub.execute_input":"2024-01-06T22:49:36.00567Z","iopub.status.idle":"2024-01-06T22:49:45.878496Z","shell.execute_reply.started":"2024-01-06T22:49:36.005642Z","shell.execute_reply":"2024-01-06T22:49:45.877536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cosine_similarity(v1, v2):\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:49:51.04067Z","iopub.execute_input":"2024-01-06T22:49:51.04104Z","iopub.status.idle":"2024-01-06T22:49:51.045994Z","shell.execute_reply.started":"2024-01-06T22:49:51.041012Z","shell.execute_reply":"2024-01-06T22:49:51.045043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word = 'taxi'\nword_vector = ft.get_sentence_vector(word)\n\nsimilarity_scores = []\nfor label, label_vector in encoded_labels.items():\n    similarity_scores.append(cosine_similarity(word_vector, label_vector))","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:55:17.446184Z","iopub.execute_input":"2024-01-06T22:55:17.447098Z","iopub.status.idle":"2024-01-06T22:55:17.503311Z","shell.execute_reply.started":"2024-01-06T22:55:17.447043Z","shell.execute_reply":"2024-01-06T22:55:17.502279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins = np.linspace(0, 1, 21)\n\nplt.hist(similarity_scores, bins=bins, edgecolor='black')\nplt.title(f'Cosine Similarity Distribution to \"{word}\"')\nplt.xlabel('Cosine Similarity')\nplt.ylabel('Frequency')\nplt.xticks(np.arange(0, 1.1, 0.1))\nplt.grid(axis='y')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:55:20.195427Z","iopub.execute_input":"2024-01-06T22:55:20.196518Z","iopub.status.idle":"2024-01-06T22:55:20.536225Z","shell.execute_reply.started":"2024-01-06T22:55:20.196439Z","shell.execute_reply":"2024-01-06T22:55:20.535315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.4\nsimilar_words_set = set()\n\nfor label, label_vector in encoded_labels.items():\n    similarity_score = cosine_similarity(word_vector, label_vector)\n    if similarity_score > threshold:\n        similar_words_set.add(label)\n        \nprint(similar_words_set)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:55:30.673847Z","iopub.execute_input":"2024-01-06T22:55:30.674691Z","iopub.status.idle":"2024-01-06T22:55:30.739847Z","shell.execute_reply.started":"2024-01-06T22:55:30.674657Z","shell.execute_reply":"2024-01-06T22:55:30.738842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"taxi_words = [\n    'hello',\n    'goodbye',\n    'help',\n    'thank you',\n    'sorry',\n    'yes',\n    'no',\n    'stop',\n    'go',\n    'left',\n    'right',\n    'ahead',\n    'around',\n    'address',\n    'destination',\n    'time',\n    'money',\n    'cost',\n    'lost',\n    'map',\n    'street',\n    'road',\n    'taxi',\n    'car',\n    'bus',\n    'school',\n    'university',\n    'food',\n    'fuel',\n]\n\nlen(taxi_words)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:55:38.484938Z","iopub.execute_input":"2024-01-06T22:55:38.485307Z","iopub.status.idle":"2024-01-06T22:55:38.493605Z","shell.execute_reply.started":"2024-01-06T22:55:38.48528Z","shell.execute_reply":"2024-01-06T22:55:38.492457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"taxi_dir = '/kaggle/working/Vector Encoded Samples'\nos.makedirs(taxi_dir, exist_ok=True)\n\nfor i in tqdm(range(len(taxi_words)), ncols=100):\n    taxi_vector = ft.get_sentence_vector(taxi_words[i])\n    taxi_path = os.path.join(taxi_dir, f'{taxi_words[i]}.npy')\n    np.save(taxi_path, taxi_vector)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:53:15.221074Z","iopub.execute_input":"2024-01-05T12:53:15.221874Z","iopub.status.idle":"2024-01-05T12:53:15.251756Z","shell.execute_reply.started":"2024-01-05T12:53:15.221812Z","shell.execute_reply":"2024-01-05T12:53:15.248284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"taxi_dir = '/kaggle/input/asl-citizen-encoded/Vector Encoded Samples'\ntaxi_vectors = []\n\nfor filename in os.listdir(taxi_dir):\n    if filename.endswith('.npy'):\n        taxi_vectors.append(np.load(os.path.join(taxi_dir, filename), allow_pickle=True))\n        \nlen(taxi_vectors)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:56:10.529868Z","iopub.execute_input":"2024-01-06T22:56:10.530716Z","iopub.status.idle":"2024-01-06T22:56:10.64483Z","shell.execute_reply.started":"2024-01-06T22:56:10.530661Z","shell.execute_reply":"2024-01-06T22:56:10.643858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.4\nsimilar_words_set = set()\n\nfor label, label_vector in encoded_labels.items():\n    for taxi_vector in taxi_vectors:\n        similarity_score = cosine_similarity(taxi_vector, label_vector)\n        if similarity_score > threshold:\n            similar_words_set.add(label)\n            \nsimilar_words_list = list(similar_words_set)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:56:24.189614Z","iopub.execute_input":"2024-01-06T22:56:24.190503Z","iopub.status.idle":"2024-01-06T22:56:25.706963Z","shell.execute_reply.started":"2024-01-06T22:56:24.190457Z","shell.execute_reply":"2024-01-06T22:56:25.706135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(similar_words_list)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:56:25.708341Z","iopub.execute_input":"2024-01-06T22:56:25.708636Z","iopub.status.idle":"2024-01-06T22:56:25.714141Z","shell.execute_reply.started":"2024-01-06T22:56:25.708611Z","shell.execute_reply":"2024-01-06T22:56:25.713132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(f'/kaggle/working/Filtered Labels/filtered_labels_{len(similar_words_list)}.txt', 'w') as file:\n    for label in similar_words_list:\n        file.write(label + '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:56:32.379818Z","iopub.execute_input":"2024-01-06T22:56:32.380712Z","iopub.status.idle":"2024-01-06T22:56:32.385907Z","shell.execute_reply.started":"2024-01-06T22:56:32.380678Z","shell.execute_reply":"2024-01-06T22:56:32.384989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del ft\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:09.821596Z","iopub.execute_input":"2024-01-06T22:57:09.821971Z","iopub.status.idle":"2024-01-06T22:57:10.050563Z","shell.execute_reply.started":"2024-01-06T22:57:09.821943Z","shell.execute_reply":"2024-01-06T22:57:10.049616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Data_Loading\">\n    \n# **Data Loading**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/asl-citizen-encoded/Data/data.csv')\nlen(data)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:49:38.023105Z","iopub.execute_input":"2024-02-09T13:49:38.023791Z","iopub.status.idle":"2024-02-09T13:49:38.199645Z","shell.execute_reply.started":"2024-02-09T13:49:38.023761Z","shell.execute_reply":"2024-02-09T13:49:38.19815Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"83399"},"metadata":{}}]},{"cell_type":"code","source":"gloss_to_label = data[['label', 'clean label']].set_index('label').to_dict()['clean label']\ngloss_to_label['None'] = 'None'\nlen(gloss_to_label)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:49:38.201023Z","iopub.execute_input":"2024-02-09T13:49:38.201348Z","iopub.status.idle":"2024-02-09T13:49:38.297818Z","shell.execute_reply.started":"2024-02-09T13:49:38.201326Z","shell.execute_reply":"2024-02-09T13:49:38.296475Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"2732"},"metadata":{}}]},{"cell_type":"code","source":"labels = []\nwith open('/kaggle/input/asl-citizen-output/Filtered Labels/530_filtered_labels.txt', 'r') as file:\n    labels = file.read().splitlines()\nlen(labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:49:38.300491Z","iopub.execute_input":"2024-02-09T13:49:38.300832Z","iopub.status.idle":"2024-02-09T13:49:38.312191Z","shell.execute_reply.started":"2024-02-09T13:49:38.300802Z","shell.execute_reply":"2024-02-09T13:49:38.311295Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"530"},"metadata":{}}]},{"cell_type":"code","source":"filtered_hand = list(range(21))\n\nfiltered_pose = [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n\nfiltered_face = []\n\nHAND_NUM = len(filtered_hand)\nPOSE_NUM = len(filtered_pose)\nFACE_NUM = len(filtered_face)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:49:38.313673Z","iopub.execute_input":"2024-02-09T13:49:38.313984Z","iopub.status.idle":"2024-02-09T13:49:38.319506Z","shell.execute_reply.started":"2024-02-09T13:49:38.313961Z","shell.execute_reply":"2024-02-09T13:49:38.318367Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"landmarks = (\n    [x for x in filtered_hand] +\n    [x + HAND_NUM for x in filtered_hand] +\n    [x + HAND_NUM * 2 for x in filtered_pose] +\n    [x + HAND_NUM * 2 + POSE_NUM for x in filtered_face]\n)\n\nprint(landmarks)\nprint(f'\\nTotal Number: {len(landmarks)}')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:49:38.320555Z","iopub.execute_input":"2024-02-09T13:49:38.320934Z","iopub.status.idle":"2024-02-09T13:49:38.335123Z","shell.execute_reply.started":"2024-02-09T13:49:38.320912Z","shell.execute_reply":"2024-02-09T13:49:38.333543Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n\nTotal Number: 55\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(split, *paths, labels=None, landmarks=None):\n    if labels is None:\n        labels = set(data['clean label'].unique().tolist())\n\n    filtered_data = data[(data['split'] == split.lower()) & (data['clean label'].isin(labels))]\n    label_dict = dict(zip(filtered_data['video'].str.replace('.mp4', ''), filtered_data['label']))\n    video_set = set(label_dict.keys())\n\n    X, Y = [], []\n    for path in paths:\n        landmarks_dict = np.load(path, allow_pickle=True)\n        keys = [k for k in landmarks_dict.keys() if k in video_set]\n\n        if landmarks is None:\n            landmarks = list(range(landmarks_dict[keys[0]].shape[1]))\n\n        split_name = {'train': 'Training', 'test': 'Validation', 'val': 'Test'}[split.lower()]\n        print(f\"\\nLoading {split_name} data from {path}:\")\n        \n        for k in tqdm(keys, ncols=100):\n            X.append(landmarks_dict[k][:, landmarks, :])\n            Y.append(label_dict.get(k, None))\n\n    return X, Y","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:49:38.338193Z","iopub.execute_input":"2024-02-09T13:49:38.338496Z","iopub.status.idle":"2024-02-09T13:49:38.349519Z","shell.execute_reply.started":"2024-02-09T13:49:38.338474Z","shell.execute_reply":"2024-02-09T13:49:38.348371Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = load_data('train', '/kaggle/input/asl-citizen-encoded/landmarks_p1.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p2.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p3.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p4.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p5.npz',\n                             labels=labels, landmarks=landmarks)\n\nX_val, Y_val = load_data('test', '/kaggle/input/asl-citizen-encoded/landmarks_p1.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p2.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p3.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p4.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p5.npz',\n                             labels=labels, landmarks=landmarks)\n\nX_test, Y_test = load_data('val', '/kaggle/input/asl-citizen-encoded/landmarks_p1.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p2.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p3.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p4.npz',\n                             '/kaggle/input/asl-citizen-encoded/landmarks_p5.npz',\n                             labels=labels, landmarks=landmarks)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:49:38.350787Z","iopub.execute_input":"2024-02-09T13:49:38.351171Z","iopub.status.idle":"2024-02-09T13:57:36.846503Z","shell.execute_reply.started":"2024-02-09T13:49:38.351143Z","shell.execute_reply":"2024-02-09T13:57:36.844935Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nLoading Training data from /kaggle/input/asl-citizen-encoded/landmarks_p1.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1811/1811 [01:03<00:00, 28.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Training data from /kaggle/input/asl-citizen-encoded/landmarks_p2.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1743/1743 [00:48<00:00, 36.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Training data from /kaggle/input/asl-citizen-encoded/landmarks_p3.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1683/1683 [00:47<00:00, 35.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Training data from /kaggle/input/asl-citizen-encoded/landmarks_p4.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1718/1718 [00:47<00:00, 36.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Training data from /kaggle/input/asl-citizen-encoded/landmarks_p5.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1668/1668 [00:47<00:00, 35.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Validation data from /kaggle/input/asl-citizen-encoded/landmarks_p1.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1475/1475 [00:34<00:00, 43.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Validation data from /kaggle/input/asl-citizen-encoded/landmarks_p2.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1461/1461 [00:34<00:00, 42.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Validation data from /kaggle/input/asl-citizen-encoded/landmarks_p3.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1440/1440 [00:33<00:00, 43.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Validation data from /kaggle/input/asl-citizen-encoded/landmarks_p4.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1394/1394 [00:31<00:00, 43.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Validation data from /kaggle/input/asl-citizen-encoded/landmarks_p5.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1399/1399 [00:36<00:00, 38.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Test data from /kaggle/input/asl-citizen-encoded/landmarks_p1.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████████████████████████████| 432/432 [00:11<00:00, 39.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Test data from /kaggle/input/asl-citizen-encoded/landmarks_p2.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████████████████████████████| 409/409 [00:10<00:00, 38.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Test data from /kaggle/input/asl-citizen-encoded/landmarks_p3.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████████████████████████████| 495/495 [00:10<00:00, 47.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Test data from /kaggle/input/asl-citizen-encoded/landmarks_p4.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████████████████████████████| 448/448 [00:09<00:00, 49.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nLoading Test data from /kaggle/input/asl-citizen-encoded/landmarks_p5.npz:\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████████████████████████████████████████████████████████| 454/454 [00:10<00:00, 45.14it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"None_dict = np.load('/kaggle/working/None.npz', allow_pickle=True)\nNone_list = []\nfor key in None_dict:\n    None_list.append(None_dict[key][:, landmarks, :])\n    \nX_train.extend(None_list)\nY_train.extend(['None'] * len(None_list))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T13:57:36.848618Z","iopub.execute_input":"2024-02-09T13:57:36.849636Z","iopub.status.idle":"2024-02-09T13:57:37.123927Z","shell.execute_reply.started":"2024-02-09T13:57:36.84959Z","shell.execute_reply":"2024-02-09T13:57:37.122893Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"len(X_train), len(X_val), len(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:37.807503Z","iopub.execute_input":"2024-02-09T14:02:37.807889Z","iopub.status.idle":"2024-02-09T14:02:37.814756Z","shell.execute_reply.started":"2024-02-09T14:02:37.807864Z","shell.execute_reply":"2024-02-09T14:02:37.813504Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(8632, 7169, 2238)"},"metadata":{}}]},{"cell_type":"code","source":"X_train[0].shape, None_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:38.947584Z","iopub.execute_input":"2024-02-09T14:02:38.948226Z","iopub.status.idle":"2024-02-09T14:02:38.955698Z","shell.execute_reply.started":"2024-02-09T14:02:38.948195Z","shell.execute_reply":"2024-02-09T14:02:38.953515Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"((58, 55, 3), (594, 55, 3))"},"metadata":{}}]},{"cell_type":"code","source":"len(np.unique(Y_train)), len(np.unique(Y_val)), len(np.unique(Y_test))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:39.611875Z","iopub.execute_input":"2024-02-09T14:02:39.612307Z","iopub.status.idle":"2024-02-09T14:02:39.628232Z","shell.execute_reply.started":"2024-02-09T14:02:39.612279Z","shell.execute_reply":"2024-02-09T14:02:39.627114Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(590, 589, 589)"},"metadata":{}}]},{"cell_type":"code","source":"np.all(np.in1d(np.unique(Y_val), np.unique(Y_train))),\\\nnp.all(np.in1d(np.unique(Y_test), np.unique(Y_train)))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:39.964634Z","iopub.execute_input":"2024-02-09T14:02:39.965069Z","iopub.status.idle":"2024-02-09T14:02:39.987421Z","shell.execute_reply.started":"2024-02-09T14:02:39.965039Z","shell.execute_reply":"2024-02-09T14:02:39.985824Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(True, True)"},"metadata":{}}]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:45.464427Z","iopub.execute_input":"2024-02-09T14:02:45.464806Z","iopub.status.idle":"2024-02-09T14:02:45.788112Z","shell.execute_reply.started":"2024-02-09T14:02:45.46478Z","shell.execute_reply":"2024-02-09T14:02:45.787171Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"595"},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Data_Augmentation\">\n    \n# **Data Augmentation**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"def rotate(data, rotation_matrix):\n    frames, landmarks, _ = data.shape\n    center = np.array([0.5, 0.5, 0])\n    non_zero = np.argwhere(np.any(data[:, :, :2] != 0, axis=2))\n    data = data.reshape(-1, 3)\n    data[non_zero] -= center\n    data[non_zero] = np.dot(data[non_zero], rotation_matrix.T)\n    data[non_zero] += center\n    data = data.reshape(frames, landmarks, 3)\n    out_of_range = np.any((data[:, :, :2] < 0) | (data[:, :, :2] > 1), axis=2)\n    data[out_of_range] = 0\n    return data\n\ndef rotate_z(data):\n    angle = np.random.choice([np.random.uniform(-30, -10),\n                              np.random.uniform(10, 30)])\n    theta = np.radians(angle)\n    rotation_matrix = np.array([\n        [np.cos(theta), -np.sin(theta), 0],\n        [np.sin(theta), np.cos(theta), 0],\n        [0, 0, 1]\n    ])\n    return rotate(data, rotation_matrix)\n\ndef rotate_y(data):\n    angle = np.random.choice([np.random.uniform(-30, -10),\n                              np.random.uniform(10, 30)])\n    theta = np.radians(angle)\n    rotation_matrix = np.array([\n        [np.cos(theta), 0, np.sin(theta)],\n        [0, 1, 0],\n        [-np.sin(theta), 0, np.cos(theta)]\n    ])\n    return rotate(data, rotation_matrix)\n\ndef rotate_x(data):\n    angle = np.random.choice([np.random.uniform(-30, -10),\n                              np.random.uniform(10, 30)])\n    theta = np.radians(angle)\n    rotation_matrix = np.array([\n        [1, 0, 0],\n        [0, np.cos(theta), -np.sin(theta)],\n        [0, np.sin(theta), np.cos(theta)]\n    ])\n    return rotate(data, rotation_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:50.035222Z","iopub.execute_input":"2024-02-09T14:02:50.035647Z","iopub.status.idle":"2024-02-09T14:02:50.050094Z","shell.execute_reply.started":"2024-02-09T14:02:50.03562Z","shell.execute_reply":"2024-02-09T14:02:50.049239Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def zoom(data):\n    factor = np.random.uniform(0.8, 1.2)\n    center = np.array([0.5, 0.5])\n    non_zero = np.argwhere(np.any(data[:, :, :2] != 0, axis=2))\n    data[non_zero[:, 0], non_zero[:, 1], :2] = (\n        (data[non_zero[:, 0], non_zero[:, 1], :2] - center) * factor + center\n    )\n    out_of_range = np.any((data[:, :, :2] < 0) | (data[:, :, :2] > 1), axis=2)\n    data[out_of_range] = 0\n    return data\n\ndef shift(data):\n    x_shift = np.random.uniform(-0.2, 0.2)\n    y_shift = np.random.uniform(-0.2, 0.2)\n    non_zero = np.argwhere(np.any(data[:, :, :2] != 0, axis=2))\n    data[non_zero[:, 0], non_zero[:, 1], 0] += x_shift\n    data[non_zero[:, 0], non_zero[:, 1], 1] += y_shift\n    out_of_range = np.any((data[:, :, :2] < 0) | (data[:, :, :2] > 1), axis=2)\n    data[out_of_range] = 0\n    return data\n\ndef mask(data):\n    frames, landmarks, _ = data.shape\n    num_hands = int(0.3 * 42)\n    num_rest = int(0.6 * (landmarks - 42))\n\n    mask = np.zeros(landmarks, dtype=bool)\n    indices = np.concatenate([\n        np.random.choice(42, num_hands, replace=False),\n        np.random.choice(landmarks - 42, num_rest, replace=False) + 42\n    ])\n    mask[indices] = True\n    data[:, mask] = 0\n    return data\n\ndef speedup(data):\n    return data[::2]","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:50.25549Z","iopub.execute_input":"2024-02-09T14:02:50.255932Z","iopub.status.idle":"2024-02-09T14:02:50.267314Z","shell.execute_reply.started":"2024-02-09T14:02:50.255901Z","shell.execute_reply":"2024-02-09T14:02:50.266267Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def apply_augmentations(data):\n    aug_functions = [rotate_x, rotate_y, rotate_z, zoom, shift, mask, speedup]\n    np.random.shuffle(aug_functions)\n    counter = 0\n    for fun in aug_functions:\n        if np.random.rand() < 0.5:\n            data = fun(data)\n            counter += 1\n    \n    if counter == 0:\n        data = apply_augmentations(data)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:50.513347Z","iopub.execute_input":"2024-02-09T14:02:50.513989Z","iopub.status.idle":"2024-02-09T14:02:50.521735Z","shell.execute_reply.started":"2024-02-09T14:02:50.513954Z","shell.execute_reply":"2024-02-09T14:02:50.519835Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def augment(X, Y, num=None):\n    X_aug = X.copy()\n    Y_aug = Y.copy()\n    \n    if num == None:\n        for i in tqdm(range(len(Y)), ncols=100):\n            num_aug = np.random.choice([1, 2, 3])\n            for n in range(num_aug):\n                X_aug.append(apply_augmentations(X[i].copy()))\n                Y_aug.append(Y[i])\n    elif num > 0:\n        for i in tqdm(range(len(Y)), ncols=100):\n            for n in range(num):\n                X_aug.append(apply_augmentations(X[i].copy()))\n                Y_aug.append(Y[i])\n\n    return X_aug, Y_aug","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:50.780827Z","iopub.execute_input":"2024-02-09T14:02:50.781739Z","iopub.status.idle":"2024-02-09T14:02:50.78835Z","shell.execute_reply.started":"2024-02-09T14:02:50.781707Z","shell.execute_reply":"2024-02-09T14:02:50.787531Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = augment(X_train, Y_train, num=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:02:51.026666Z","iopub.execute_input":"2024-02-09T14:02:51.027153Z","iopub.status.idle":"2024-02-09T14:03:16.101662Z","shell.execute_reply.started":"2024-02-09T14:02:51.027119Z","shell.execute_reply":"2024-02-09T14:03:16.100648Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"100%|██████████████████████████████████████████████████████████| 8632/8632 [00:25<00:00, 344.39it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"len(X_train), len(X_train[0]), len(X_train[0][0]), len(X_train[0][0][0])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:16.103694Z","iopub.execute_input":"2024-02-09T14:03:16.104048Z","iopub.status.idle":"2024-02-09T14:03:16.113202Z","shell.execute_reply.started":"2024-02-09T14:03:16.104021Z","shell.execute_reply":"2024-02-09T14:03:16.112083Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(17264, 58, 55, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Data_Preprocessing\">\n    \n# **Data Preprocessing**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"seed_value = 42\nnp.random.seed(seed_value)\n\npermutation_train = np.random.permutation(len(Y_train))\npermutation_val = np.random.permutation(len(Y_val))\npermutation_test = np.random.permutation(len(Y_test))\n\nX_train = [X_train[i] for i in permutation_train]\nY_train = [Y_train[i] for i in permutation_train]\n\nX_val = [X_val[i] for i in permutation_val]\nY_val = [Y_val[i] for i in permutation_val]\n\nX_test = [X_test[i] for i in permutation_test]\nY_test = [Y_test[i] for i in permutation_test]","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:16.11465Z","iopub.execute_input":"2024-02-09T14:03:16.114992Z","iopub.status.idle":"2024-02-09T14:03:16.140144Z","shell.execute_reply.started":"2024-02-09T14:03:16.114965Z","shell.execute_reply":"2024-02-09T14:03:16.138734Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"max(len(x) for x in X_train), max(len(x) for x in X_val), max(len(x) for x in X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:16.142452Z","iopub.execute_input":"2024-02-09T14:03:16.142808Z","iopub.status.idle":"2024-02-09T14:03:16.16681Z","shell.execute_reply.started":"2024-02-09T14:03:16.14278Z","shell.execute_reply":"2024-02-09T14:03:16.165624Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(923, 373, 208)"},"metadata":{}}]},{"cell_type":"code","source":"sum(len(x) for x in X_train) / len(X_train),\\\nsum(len(x) for x in X_val) / len(X_val),\\\nsum(len(x) for x in X_test) / len(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:16.16824Z","iopub.execute_input":"2024-02-09T14:03:16.168656Z","iopub.status.idle":"2024-02-09T14:03:16.190811Z","shell.execute_reply.started":"2024-02-09T14:03:16.168621Z","shell.execute_reply":"2024-02-09T14:03:16.189127Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(73.59951343836886, 75.43004603152463, 85.20464700625558)"},"metadata":{}}]},{"cell_type":"markdown","source":"<h3><b>Method 1:</b> Padding","metadata":{}},{"cell_type":"code","source":"def padding(X, Y, length=None, pad=0):\n    if length is None:\n        length = max(len(x) for x in X)\n    \n    X_padded = []\n    for x in X:\n        if len(x) > length:\n            X_padded.append(x[:length]) #truncate\n        else:\n            pad_length = length - len(x)\n            X_padded.append(np.pad(\n                x, ((0, pad_length), (0, 0), (0, 0)),\n                mode='constant', constant_values=pad\n            ))\n            \n    X_padded = np.array(X_padded)\n    Y = np.array(Y)\n    return X_padded, Y","metadata":{"execution":{"iopub.status.busy":"2024-01-26T21:54:36.237907Z","iopub.execute_input":"2024-01-26T21:54:36.238794Z","iopub.status.idle":"2024-01-26T21:54:36.245593Z","shell.execute_reply.started":"2024-01-26T21:54:36.238758Z","shell.execute_reply":"2024-01-26T21:54:36.244536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = padding(X_train, Y_train, length=120, pad=-100)\nX_val, Y_val = padding(X_val, Y_val, length=120, pad=-100)\nX_test, Y_test = padding(X_test, Y_test, length=120, pad=-100)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T21:54:36.441129Z","iopub.execute_input":"2024-01-26T21:54:36.441733Z","iopub.status.idle":"2024-01-26T21:54:45.04705Z","shell.execute_reply.started":"2024-01-26T21:54:36.441702Z","shell.execute_reply":"2024-01-26T21:54:45.046108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_val.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-26T21:54:45.052384Z","iopub.execute_input":"2024-01-26T21:54:45.052705Z","iopub.status.idle":"2024-01-26T21:54:45.059065Z","shell.execute_reply.started":"2024-01-26T21:54:45.052678Z","shell.execute_reply":"2024-01-26T21:54:45.058051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> <b>Method 2:</b> Sequencing","metadata":{}},{"cell_type":"code","source":"def sequences(X, Y, length=30, step=1, pad=0):\n    X_sequences = []\n    Y_sequences = []\n\n    for inputs, label in zip(X, Y):\n        num = inputs.shape[0]\n\n        if num < length:\n            padding = length - num\n            inputs = np.pad(\n            inputs, ((0, padding), (0, 0), (0, 0)),\n            mode='constant', constant_values=pad\n            )\n            num = length\n\n        for start in range(0, num - length + 1, step):\n            end = start + length\n            sequence = inputs[start:end]\n            X_sequences.append(sequence)\n            Y_sequences.append(label)\n\n    X_sequences = np.array(X_sequences)\n    Y_sequences = np.array(Y_sequences)\n    return X_sequences, Y_sequences","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = sequences(X_train, Y_train, length=60, step=20, pad=-100)\nX_val, Y_val = sequences(X_val, Y_val, length=60, step=20, pad=-100)\nX_test, Y_test = sequences(X_test, Y_test, length=60, step=20, pad=-100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_val.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> <b>Method 3:</b> Interpolation","metadata":{}},{"cell_type":"code","source":"def interpolate(X, Y, length=100):\n    X_interpolated = [np.apply_along_axis(lambda arr: np.interp(np.linspace(0, 1, length),\n                                                                np.linspace(0, 1, arr.shape[0]),\n                                                                arr), axis=0, arr=x) for x in X]\n    \n    X = np.array(X_interpolated)\n    Y = np.array(Y)\n    return X, Y","metadata":{"execution":{"iopub.status.busy":"2024-01-25T02:56:16.701498Z","iopub.execute_input":"2024-01-25T02:56:16.701983Z","iopub.status.idle":"2024-01-25T02:56:16.70895Z","shell.execute_reply.started":"2024-01-25T02:56:16.701948Z","shell.execute_reply":"2024-01-25T02:56:16.70785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = interpolate(X_train, Y_train, length=100)\nX_val, Y_val = interpolate(X_val, Y_val, length=100)\nX_test, Y_test = interpolate(X_test, Y_test, length=100)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T02:56:16.972342Z","iopub.execute_input":"2024-01-25T02:56:16.972915Z","iopub.status.idle":"2024-01-25T03:05:44.242248Z","shell.execute_reply.started":"2024-01-25T02:56:16.972888Z","shell.execute_reply":"2024-01-25T03:05:44.24137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_val.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-25T03:06:05.36013Z","iopub.execute_input":"2024-01-25T03:06:05.360558Z","iopub.status.idle":"2024-01-25T03:06:05.367465Z","shell.execute_reply.started":"2024-01-25T03:06:05.360526Z","shell.execute_reply":"2024-01-25T03:06:05.366455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> <b>Method 4:</b> Padding from the center","metadata":{}},{"cell_type":"code","source":"def padding(X, Y, length=None, pad=0):\n    if length is None:\n        length = max(len(x) for x in X)\n    \n    X_padded = []\n    for x in X:\n        if len(x) > length:\n            start = (len(x) - length) // 2\n            end = start + length\n            X_padded.append(x[start:end])\n        else:\n            pad_before = (length - len(x)) // 2\n            pad_after = length - len(x) - pad_before\n            X_padded.append(np.pad(\n                x, ((pad_before, pad_after), (0, 0), (0, 0)),\n                mode='constant', constant_values=pad\n            ))\n            \n    X_padded = np.array(X_padded)\n    Y = np.array(Y)\n    return X_padded, Y","metadata":{"execution":{"iopub.status.busy":"2024-02-08T00:06:17.033327Z","iopub.execute_input":"2024-02-08T00:06:17.033681Z","iopub.status.idle":"2024-02-08T00:06:17.041526Z","shell.execute_reply.started":"2024-02-08T00:06:17.033652Z","shell.execute_reply":"2024-02-08T00:06:17.040488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = padding(X_train, Y_train, length=120, pad=0)\nX_val, Y_val = padding(X_val, Y_val, length=120, pad=0)\nX_test, Y_test = padding(X_test, Y_test, length=120, pad=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T04:59:02.650686Z","iopub.execute_input":"2024-02-07T04:59:02.650953Z","iopub.status.idle":"2024-02-07T04:59:10.717606Z","shell.execute_reply.started":"2024-02-07T04:59:02.650932Z","shell.execute_reply":"2024-02-07T04:59:10.716581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_val.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-07T04:59:10.71872Z","iopub.execute_input":"2024-02-07T04:59:10.718983Z","iopub.status.idle":"2024-02-07T04:59:10.728308Z","shell.execute_reply.started":"2024-02-07T04:59:10.718961Z","shell.execute_reply":"2024-02-07T04:59:10.727462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> <b>Method 5:</b> Padding with None","metadata":{}},{"cell_type":"code","source":"def padding_with_none(X, Y, length=None):\n    if length is None:\n        length = max(len(x) for x in X)\n    \n    X_padded = []\n    for x in X:\n        if len(x) > length:\n            start = (len(x) - length) // 2\n            end = start + length\n            X_padded.append(x[start:end])\n        else:\n            pad_before = (length - len(x)) // 2\n            pad_after = length - len(x) - pad_before\n            idx = np.random.choice(len(None_list))\n            none_sample = None_list[idx]\n            selected_frames = np.random.choice(len(none_sample), size=(pad_before + pad_after,), replace=True)\n            padding_samples = none_sample[selected_frames]\n            padded_x = np.concatenate([padding_samples[:pad_before], x, padding_samples[pad_before:]], axis=0)\n            X_padded.append(padded_x)\n            \n    X_padded = np.array(X_padded)\n    Y = np.array(Y)\n    return X_padded, Y","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:16.192779Z","iopub.execute_input":"2024-02-09T14:03:16.193388Z","iopub.status.idle":"2024-02-09T14:03:16.202556Z","shell.execute_reply.started":"2024-02-09T14:03:16.193283Z","shell.execute_reply":"2024-02-09T14:03:16.201473Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = padding_with_none(X_train, Y_train, length=120)\nX_val, Y_val = padding_with_none(X_val, Y_val, length=120)\nX_test, Y_test = padding_with_none(X_test, Y_test, length=120)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:16.204151Z","iopub.execute_input":"2024-02-09T14:03:16.20455Z","iopub.status.idle":"2024-02-09T14:03:22.795523Z","shell.execute_reply.started":"2024-02-09T14:03:16.204519Z","shell.execute_reply":"2024-02-09T14:03:22.794588Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_val.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:22.796552Z","iopub.execute_input":"2024-02-09T14:03:22.797301Z","iopub.status.idle":"2024-02-09T14:03:22.804751Z","shell.execute_reply.started":"2024-02-09T14:03:22.797273Z","shell.execute_reply":"2024-02-09T14:03:22.803097Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"((17264, 120, 55, 3), (7169, 120, 55, 3), (2238, 120, 55, 3))"},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Label_Encoding\">\n    \n# **Label Encoding**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"glosses = pd.unique(Y_train) #preserve order\nlen(glosses)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:56.898865Z","iopub.execute_input":"2024-02-09T14:03:56.899269Z","iopub.status.idle":"2024-02-09T14:03:56.915258Z","shell.execute_reply.started":"2024-02-09T14:03:56.899244Z","shell.execute_reply":"2024-02-09T14:03:56.913658Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"590"},"metadata":{}}]},{"cell_type":"code","source":"gloss_mapping = {gloss: idx for idx, gloss in enumerate(glosses)}\nwith open(f'/kaggle/working/Filtered Labels/{len(glosses)}_gloss_mapping.json', 'w') as json_file:\n    json.dump(gloss_mapping, json_file, indent=4)\n    \nindex_gloss_mapping = {idx: gloss for gloss, idx in gloss_mapping.items()}\nwith open(f'/kaggle/working/Filtered Labels/{len(glosses)}_index_gloss_mapping.json', 'w') as json_file:\n    json.dump(index_gloss_mapping, json_file, indent=4)\n    \nindex_label_mapping = {idx: gloss_to_label[gloss] for gloss, idx in gloss_mapping.items()}\nwith open(f'/kaggle/working/Filtered Labels/{len(glosses)}_index_label_mapping.json', 'w') as json_file:\n    json.dump(index_label_mapping, json_file, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:57.157386Z","iopub.execute_input":"2024-02-09T14:03:57.157987Z","iopub.status.idle":"2024-02-09T14:03:57.169345Z","shell.execute_reply.started":"2024-02-09T14:03:57.157954Z","shell.execute_reply":"2024-02-09T14:03:57.168057Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"Y_train= np.array([gloss_mapping[label] for label in Y_train])\nY_val = np.array([gloss_mapping[label] for label in Y_val])\nY_test = np.array([gloss_mapping[label] for label in Y_test])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:57.454522Z","iopub.execute_input":"2024-02-09T14:03:57.455386Z","iopub.status.idle":"2024-02-09T14:03:57.47066Z","shell.execute_reply.started":"2024-02-09T14:03:57.455356Z","shell.execute_reply":"2024-02-09T14:03:57.469709Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"Y_train","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:57.885657Z","iopub.execute_input":"2024-02-09T14:03:57.886309Z","iopub.status.idle":"2024-02-09T14:03:57.892204Z","shell.execute_reply.started":"2024-02-09T14:03:57.886272Z","shell.execute_reply":"2024-02-09T14:03:57.891317Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"array([  0,   1,   2, ..., 564, 349, 550])"},"metadata":{}}]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:03:58.228251Z","iopub.execute_input":"2024-02-09T14:03:58.228674Z","iopub.status.idle":"2024-02-09T14:03:58.486114Z","shell.execute_reply.started":"2024-02-09T14:03:58.228643Z","shell.execute_reply":"2024-02-09T14:03:58.48521Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"99"},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Model_Training\">\n    \n# **Model Training**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"gc.collect()\ntf.keras.backend.clear_session()\nphysical_devices = tf.config.list_physical_devices('GPU')\nfor device in physical_devices:\n    tf.config.experimental.set_memory_growth(device, True)\nphysical_devices","metadata":{"execution":{"iopub.status.busy":"2024-02-01T02:33:08.080907Z","iopub.execute_input":"2024-02-01T02:33:08.081299Z","iopub.status.idle":"2024-02-01T02:33:08.310329Z","shell.execute_reply.started":"2024-02-01T02:33:08.081271Z","shell.execute_reply":"2024-02-01T02:33:08.308952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Reshape((X_train[0].shape[0], -1), input_shape=X_train[0].shape),\n\n    tf.keras.layers.Conv1D(128, 1, strides=1, padding='valid', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.DepthwiseConv1D(3, strides=1, padding='valid', depth_multiplier=1, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Conv1D(128, 1, strides=1, padding='valid', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.DepthwiseConv1D(5, strides=2, padding='valid', depth_multiplier=4, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.MaxPool1D(2, 2),\n\n    tf.keras.layers.Conv1D(256, 1, strides=1, padding='valid', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.DepthwiseConv1D(3, strides=1, padding='valid', depth_multiplier=1, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Conv1D(256, 1, strides=1, padding='valid', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.DepthwiseConv1D(5, strides=2, padding='valid', depth_multiplier=4, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.GlobalAvgPool1D(),\n    tf.keras.layers.Dropout(rate=0.5),\n\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate=0.5),\n\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(rate=0.5),\n\n    tf.keras.layers.Dense(len(glosses), activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:35:08.229723Z","iopub.execute_input":"2024-01-29T18:35:08.230118Z","iopub.status.idle":"2024-01-29T18:35:08.980725Z","shell.execute_reply.started":"2024-01-29T18:35:08.230082Z","shell.execute_reply":"2024-01-29T18:35:08.979889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.01,\n    decay_steps=1000,\n    decay_rate=0.9\n)\n\nacc_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath='best_accuracy_weights.h5',\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True,\n)\n\nloss_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath='best_loss_weights.h5',\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True,\n)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    patience=100,\n    restore_best_weights=True\n)\n\nmodel.compile(\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T20:11:17.156688Z","iopub.execute_input":"2024-01-31T20:11:17.157298Z","iopub.status.idle":"2024-01-31T20:11:17.163857Z","shell.execute_reply.started":"2024-01-31T20:11:17.157265Z","shell.execute_reply":"2024-01-31T20:11:17.162836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    hist = model.fit(\n        X_train, Y_train,\n        validation_data=(X_val, Y_val),\n        epochs=1000,\n        batch_size=128,\n        callbacks=[acc_checkpoint, loss_checkpoint, early_stopping]\n    )\n    \nexcept KeyboardInterrupt:\n    model.load_weights('best_accuracy_weights.h5')\n    print(\"\\nManual interruption detected. Training stopped.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_weights('best_loss_weights.h5')\ndel X_train, Y_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:59:40.608323Z","iopub.execute_input":"2024-01-29T18:59:40.609074Z","iopub.status.idle":"2024-01-29T18:59:40.985905Z","shell.execute_reply.started":"2024-01-29T18:59:40.609037Z","shell.execute_reply":"2024-01-29T18:59:40.98501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_val, Y_val)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:59:43.082995Z","iopub.execute_input":"2024-01-29T18:59:43.083822Z","iopub.status.idle":"2024-01-29T18:59:46.027855Z","shell.execute_reply.started":"2024-01-29T18:59:43.083789Z","shell.execute_reply":"2024-01-29T18:59:46.026976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test, Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:00:58.348693Z","iopub.execute_input":"2024-01-29T19:00:58.349585Z","iopub.status.idle":"2024-01-29T19:00:59.094814Z","shell.execute_reply.started":"2024-01-29T19:00:58.349547Z","shell.execute_reply":"2024-01-29T19:00:59.093693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_val, Y_val\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:59:51.38249Z","iopub.execute_input":"2024-01-29T18:59:51.382865Z","iopub.status.idle":"2024-01-29T18:59:51.647021Z","shell.execute_reply.started":"2024-01-29T18:59:51.382835Z","shell.execute_reply":"2024-01-29T18:59:51.646067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Transformer_Experiment\">\n    \n# **Transformer Experiment 2**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow-addons\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T00:54:27.635044Z","iopub.execute_input":"2024-02-09T00:54:27.635828Z","iopub.status.idle":"2024-02-09T00:54:57.507992Z","shell.execute_reply.started":"2024-02-09T00:54:27.635796Z","shell.execute_reply":"2024-02-09T00:54:57.507031Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntf.keras.backend.clear_session()\nphysical_devices = tf.config.list_physical_devices('GPU')\nfor device in physical_devices:\n    tf.config.experimental.set_memory_growth(device, True)\nphysical_devices","metadata":{"execution":{"iopub.status.busy":"2024-02-09T00:55:00.497069Z","iopub.execute_input":"2024-02-09T00:55:00.498372Z","iopub.status.idle":"2024-02-09T00:55:01.015145Z","shell.execute_reply.started":"2024-02-09T00:55:00.498336Z","shell.execute_reply":"2024-02-09T00:55:01.014068Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"},"metadata":{}}]},{"cell_type":"code","source":"class ECA(tf.keras.layers.Layer):\n    def __init__(self, kernel_size=5, **kwargs):\n        super().__init__(**kwargs)\n        self.supports_masking = True\n        self.kernel_size = kernel_size\n        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n\n    def call(self, inputs, mask=None):\n        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n        nn = tf.expand_dims(nn, -1)\n        nn = self.conv(nn)\n        nn = tf.squeeze(nn, -1)\n        nn = tf.nn.sigmoid(nn)\n        nn = nn[:,None,:]\n        return inputs * nn\n\nclass LateDropout(tf.keras.layers.Layer):\n    def __init__(self, rate, noise_shape=None, start_step=0, **kwargs):\n        super().__init__(**kwargs)\n        self.supports_masking = True\n        self.rate = rate\n        self.start_step = start_step\n        self.dropout = tf.keras.layers.Dropout(rate, noise_shape=noise_shape)\n      \n    def build(self, input_shape):\n        super().build(input_shape)\n        agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n        self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg, trainable=False)\n\n    def call(self, inputs, training=False):\n        x = tf.cond(self._train_counter < self.start_step, lambda:inputs, lambda:self.dropout(inputs, training=training))\n        if training:\n            self._train_counter.assign_add(1)\n        return x\n\nclass CausalDWConv1D(tf.keras.layers.Layer):\n    def __init__(self, \n        kernel_size=17,\n        dilation_rate=1,\n        use_bias=False,\n        depthwise_initializer='glorot_uniform',\n        name='', **kwargs):\n        super().__init__(name=name,**kwargs)\n        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n                            kernel_size,\n                            strides=1,\n                            dilation_rate=dilation_rate,\n                            padding='valid',\n                            use_bias=use_bias,\n                            depthwise_initializer=depthwise_initializer,\n                            name=name + '_dwconv')\n        self.supports_masking = True\n        \n    def call(self, inputs):\n        x = self.causal_pad(inputs)\n        x = self.dw_conv(x)\n        return x\n\ndef Conv1DBlock(channel_size,\n          kernel_size,\n          dilation_rate=1,\n          drop_rate=0.0,\n          expand_ratio=2,\n          se_ratio=0.25,\n          activation='swish',\n          name=None):\n\n    if name is None:\n        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n    # Expansion phase\n    def apply(inputs):\n        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n        channels_expand = channels_in * expand_ratio\n\n        skip = inputs\n\n        x = tf.keras.layers.Dense(\n            channels_expand,\n            use_bias=True,\n            activation=activation,\n            name=name + '_expand_conv')(inputs)\n\n        # Depthwise Convolution\n        x = CausalDWConv1D(kernel_size,\n            dilation_rate=dilation_rate,\n            use_bias=False,\n            name=name + '_dwconv')(x)\n\n        x = tf.keras.layers.BatchNormalization(momentum=0.95, name=name + '_bn')(x)\n\n        x  = ECA()(x)\n\n        x = tf.keras.layers.Dense(\n            channel_size,\n            use_bias=True,\n            name=name + '_project_conv')(x)\n\n        if drop_rate > 0:\n            x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1), name=name + '_drop')(x)\n\n        if (channels_in == channel_size):\n            x = tf.keras.layers.add([x, skip], name=name + '_add')\n        return x\n\n    return apply","metadata":{"execution":{"iopub.status.busy":"2024-02-09T00:55:01.017523Z","iopub.execute_input":"2024-02-09T00:55:01.017931Z","iopub.status.idle":"2024-02-09T00:55:01.044714Z","shell.execute_reply.started":"2024-02-09T00:55:01.017894Z","shell.execute_reply":"2024-02-09T00:55:01.043722Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class MultiHeadSelfAttention(tf.keras.layers.Layer):\n    def __init__(self, dim=256, num_heads=4, dropout=0, **kwargs):\n        super().__init__(**kwargs)\n        self.dim = dim\n        self.scale = self.dim ** -0.5\n        self.num_heads = num_heads\n        self.qkv = tf.keras.layers.Dense(3 * dim, use_bias=False)\n        self.drop1 = tf.keras.layers.Dropout(dropout)\n        self.proj = tf.keras.layers.Dense(dim, use_bias=False)\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        qkv = self.qkv(inputs)\n        qkv = tf.keras.layers.Permute((2, 1, 3))(tf.keras.layers.Reshape((-1, self.num_heads, self.dim * 3 // self.num_heads))(qkv))\n        q, k, v = tf.split(qkv, [self.dim // self.num_heads] * 3, axis=-1)\n\n        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n\n        if mask is not None:\n            mask = mask[:, None, None, :]\n\n        attn = tf.keras.layers.Softmax(axis=-1)(attn, mask=mask)\n        attn = self.drop1(attn)\n\n        x = attn @ v\n        x = tf.keras.layers.Reshape((-1, self.dim))(tf.keras.layers.Permute((2, 1, 3))(x))\n        x = self.proj(x)\n        return x\n\n\ndef TransformerBlock(dim=256, num_heads=4, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n    def apply(inputs):\n        x = inputs\n        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n        x = MultiHeadSelfAttention(dim=dim,num_heads=num_heads,dropout=attn_dropout)(x)\n        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n        x = tf.keras.layers.Add()([inputs, x])\n        attn_out = x\n\n        x = tf.keras.layers.BatchNormalization(momentum=0.95)(x)\n        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n        x = tf.keras.layers.Add()([attn_out, x])\n        return x\n    return apply","metadata":{"execution":{"iopub.status.busy":"2024-02-09T00:55:02.313508Z","iopub.execute_input":"2024-02-09T00:55:02.314266Z","iopub.status.idle":"2024-02-09T00:55:02.329578Z","shell.execute_reply.started":"2024-02-09T00:55:02.31423Z","shell.execute_reply":"2024-02-09T00:55:02.32857Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class OneCycleLR(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self,\n                lr=1e-4,\n                epochs=10,\n                steps_per_epoch=100,\n                steps_per_update=1,\n                resume_epoch=0,\n                decay_epochs=10,\n                sustain_epochs=0,\n                warmup_epochs=0,\n                lr_start=0,\n                lr_min=0,\n                warmup_type='linear',\n                decay_type='cosine',\n                **kwargs):\n        \n        super().__init__(**kwargs)\n        self.lr = float(lr)\n        self.epochs = float(epochs)\n        self.steps_per_update = float(steps_per_update)\n        self.resume_epoch = float(resume_epoch)\n        self.steps_per_epoch = float(steps_per_epoch)\n        self.decay_epochs = float(decay_epochs)\n        self.sustain_epochs = float(sustain_epochs)\n        self.warmup_epochs = float(warmup_epochs)\n        self.lr_start = float(lr_start)\n        self.lr_min = float(lr_min)\n        self.decay_type = decay_type\n        self.warmup_type = warmup_type\n        \n\n    def __call__(self, step):\n        step = tf.cast(step, tf.float32)\n        total_steps = self.epochs * self.steps_per_epoch\n        warmup_steps = self.warmup_epochs * self.steps_per_epoch\n        sustain_steps = self.sustain_epochs * self.steps_per_epoch\n        decay_steps = self.decay_epochs * self.steps_per_epoch\n\n        if self.resume_epoch > 0:\n            step = step + self.resume_epoch * self.steps_per_epoch\n\n        step = tf.cond(step > decay_steps, lambda :decay_steps, lambda :step)\n        step = tf.math.truediv(step, self.steps_per_update) * self.steps_per_update\n\n        warmup_cond = step < warmup_steps\n        decay_cond = step >= (warmup_steps + sustain_steps)\n        \n        if self.warmup_type == 'linear':\n            lr = tf.cond(warmup_cond, lambda: tf.math.divide_no_nan(self.lr-self.lr_start , warmup_steps) * step + self.lr_start, lambda: self.lr)\n        elif self.warmup_type == 'exponential':\n            factor = tf.pow(self.lr_start, 1/warmup_steps)\n            lr = tf.cond(warmup_cond, lambda: (self.lr - self.lr_start) * factor**(warmup_steps - step) + self.lr_start, lambda: self.lr)\n        elif self.warmup_type == 'cosine':\n            lr = tf.cond(warmup_cond, lambda: 0.5 * (self.lr - self.lr_start) * (1 + tf.cos(3.14159265359 * (warmup_steps - step)  / warmup_steps)) + self.lr_start, lambda:self.lr)\n        else:\n            raise NotImplementedError\n                    \n        \n        if self.decay_type == 'linear':\n            lr = tf.cond(decay_cond, lambda: self.lr + (self.lr_min-self.lr)/(decay_steps - warmup_steps - sustain_steps)*(step - warmup_steps - sustain_steps), lambda:lr)\n        elif self.decay_type == 'exponential':\n            factor = tf.pow(self.lr_min, 1/(decay_steps - warmup_steps - sustain_steps))\n            lr = tf.cond(decay_cond, lambda: (self.lr - self.lr_min) * factor**(step - warmup_steps - sustain_steps) + self.lr_min, lambda:lr)\n        elif self.decay_type == 'cosine':\n            lr = tf.cond(decay_cond, lambda: 0.5 * (self.lr - self.lr_min) * (1 + tf.cos(3.14159265359 * (step - warmup_steps - sustain_steps) / (decay_steps - warmup_steps - sustain_steps))) + self.lr_min, lambda:lr)\n        else:\n            raise NotImplementedError\n            \n        return lr\n\n    def plot(self):\n        step = max(1, int(self.epochs*self.steps_per_epoch)//1000) #1 for total_steps < 1000, total_steps//1000 else\n        eps = list(range(0,int(self.epochs*self.steps_per_epoch),step))\n        learning_rates = [self(x) for x in eps]\n        plt.scatter(eps,learning_rates,2)\n        plt.show()\n        \n    def get_config(self):\n        config = {\n            'lr': self.lr,\n            'epochs': self.epochs,\n            'steps_per_update': self.steps_per_update,\n            'resume_epoch': self.resume_epoch,\n            'steps_per_epoch': self.steps_per_epoch,\n            'decay_epochs': self.decay_epochs,\n            'sustain_epochs': self.sustain_epochs,\n            'warmup_epochs': self.warmup_epochs,\n            'lr_start': self.lr_start,\n            'lr_min': self.lr_min,\n            'decay_type': self.decay_type,\n            'warmup_type': self.warmup_type\n        }\n        return config","metadata":{"execution":{"iopub.status.busy":"2024-02-09T00:55:03.164718Z","iopub.execute_input":"2024-02-09T00:55:03.165321Z","iopub.status.idle":"2024-02-09T00:55:03.188075Z","shell.execute_reply.started":"2024-02-09T00:55:03.165287Z","shell.execute_reply":"2024-02-09T00:55:03.187096Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def get_model(max_len=120, dropout_step=0, dim=192):\n    inp = tf.keras.layers.Input(X_train[0].shape, name='input')\n    x = inp\n    x = tf.reshape(x, [-1, X_train[0].shape[0], X_train[0].shape[1] * X_train[0].shape[2]])\n\n    ksize = 17\n    x = tf.keras.layers.Dense(dim, use_bias=False,name='stem_conv')(x)\n    x = tf.keras.layers.BatchNormalization(momentum=0.95,name='stem_bn')(x)\n\n    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n    x = Conv1DBlock(dim,ksize,drop_rate=0.2)(x)\n    x = TransformerBlock(dim,expand=2)(x)\n\n    x = Conv1DBlock(dim,ksize,drop_rate=0.25)(x)\n    x = Conv1DBlock(dim,ksize,drop_rate=0.25)(x)\n    x = Conv1DBlock(dim,ksize,drop_rate=0.25)(x)\n    x = TransformerBlock(dim,expand=2)(x)\n\n    x = tf.keras.layers.Dense(dim*2,activation=None,name='top_conv')(x)\n    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n    x = LateDropout(0.8, start_step=dropout_step)(x)\n    x = tf.keras.layers.Dense(len(glosses),name='classifier')(x)\n    \n    model = tf.keras.models.Model(inputs=inp, outputs=x)\n    \n    schedule = OneCycleLR(8e-3, 500, steps_per_epoch=192, decay_epochs=500, lr_min=1e-6, decay_type='cosine', warmup_type='linear')\n    decay_schedule = OneCycleLR(8e-4, 500, steps_per_epoch=192, decay_epochs=500, lr_min=1e-7, decay_type='cosine', warmup_type='linear')\n    optimizer = tfa.optimizers.RectifiedAdam(learning_rate=schedule, weight_decay=decay_schedule, sma_threshold=4)\n    optimizer = tfa.optimizers.Lookahead(optimizer,sync_period=5)\n    model.compile(\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    metrics=['accuracy']\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-09T00:55:20.267842Z","iopub.execute_input":"2024-02-09T00:55:20.268457Z","iopub.status.idle":"2024-02-09T00:55:20.282651Z","shell.execute_reply.started":"2024-02-09T00:55:20.268424Z","shell.execute_reply":"2024-02-09T00:55:20.281626Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodel = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T00:55:21.507615Z","iopub.execute_input":"2024-02-09T00:55:21.508024Z","iopub.status.idle":"2024-02-09T00:55:24.092958Z","shell.execute_reply.started":"2024-02-09T00:55:21.507993Z","shell.execute_reply":"2024-02-09T00:55:24.078619Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input (InputLayer)          [(None, 120, 55, 3)]         0         []                            \n                                                                                                  \n tf.reshape (TFOpLambda)     (None, 120, 165)             0         ['input[0][0]']               \n                                                                                                  \n stem_conv (Dense)           (None, 120, 192)             31680     ['tf.reshape[0][0]']          \n                                                                                                  \n stem_bn (BatchNormalizatio  (None, 120, 192)             768       ['stem_conv[0][0]']           \n n)                                                                                               \n                                                                                                  \n 1_expand_conv (Dense)       (None, 120, 384)             74112     ['stem_bn[0][0]']             \n                                                                                                  \n 1_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['1_expand_conv[0][0]']       \n                                                                                                  \n 1_bn (BatchNormalization)   (None, 120, 384)             1536      ['1_dwconv[0][0]']            \n                                                                                                  \n eca (ECA)                   (None, 120, 384)             5         ['1_bn[0][0]']                \n                                                                                                  \n 1_project_conv (Dense)      (None, 120, 192)             73920     ['eca[0][0]']                 \n                                                                                                  \n 1_drop (Dropout)            (None, 120, 192)             0         ['1_project_conv[0][0]']      \n                                                                                                  \n 1_add (Add)                 (None, 120, 192)             0         ['1_drop[0][0]',              \n                                                                     'stem_bn[0][0]']             \n                                                                                                  \n 2_expand_conv (Dense)       (None, 120, 384)             74112     ['1_add[0][0]']               \n                                                                                                  \n 2_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['2_expand_conv[0][0]']       \n                                                                                                  \n 2_bn (BatchNormalization)   (None, 120, 384)             1536      ['2_dwconv[0][0]']            \n                                                                                                  \n eca_1 (ECA)                 (None, 120, 384)             5         ['2_bn[0][0]']                \n                                                                                                  \n 2_project_conv (Dense)      (None, 120, 192)             73920     ['eca_1[0][0]']               \n                                                                                                  \n 2_drop (Dropout)            (None, 120, 192)             0         ['2_project_conv[0][0]']      \n                                                                                                  \n 2_add (Add)                 (None, 120, 192)             0         ['2_drop[0][0]',              \n                                                                     '1_add[0][0]']               \n                                                                                                  \n 3_expand_conv (Dense)       (None, 120, 384)             74112     ['2_add[0][0]']               \n                                                                                                  \n 3_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['3_expand_conv[0][0]']       \n                                                                                                  \n 3_bn (BatchNormalization)   (None, 120, 384)             1536      ['3_dwconv[0][0]']            \n                                                                                                  \n eca_2 (ECA)                 (None, 120, 384)             5         ['3_bn[0][0]']                \n                                                                                                  \n 3_project_conv (Dense)      (None, 120, 192)             73920     ['eca_2[0][0]']               \n                                                                                                  \n 3_drop (Dropout)            (None, 120, 192)             0         ['3_project_conv[0][0]']      \n                                                                                                  \n 3_add (Add)                 (None, 120, 192)             0         ['3_drop[0][0]',              \n                                                                     '2_add[0][0]']               \n                                                                                                  \n batch_normalization (Batch  (None, 120, 192)             768       ['3_add[0][0]']               \n Normalization)                                                                                   \n                                                                                                  \n multi_head_self_attention   (None, 120, 192)             147456    ['batch_normalization[0][0]'] \n (MultiHeadSelfAttention)                                                                         \n                                                                                                  \n dropout_1 (Dropout)         (None, 120, 192)             0         ['multi_head_self_attention[0]\n                                                                    [0]']                         \n                                                                                                  \n add (Add)                   (None, 120, 192)             0         ['3_add[0][0]',               \n                                                                     'dropout_1[0][0]']           \n                                                                                                  \n batch_normalization_1 (Bat  (None, 120, 192)             768       ['add[0][0]']                 \n chNormalization)                                                                                 \n                                                                                                  \n dense_2 (Dense)             (None, 120, 384)             73728     ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n dense_3 (Dense)             (None, 120, 192)             73728     ['dense_2[0][0]']             \n                                                                                                  \n dropout_2 (Dropout)         (None, 120, 192)             0         ['dense_3[0][0]']             \n                                                                                                  \n add_1 (Add)                 (None, 120, 192)             0         ['add[0][0]',                 \n                                                                     'dropout_2[0][0]']           \n                                                                                                  \n 4_expand_conv (Dense)       (None, 120, 384)             74112     ['add_1[0][0]']               \n                                                                                                  \n 4_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['4_expand_conv[0][0]']       \n                                                                                                  \n 4_bn (BatchNormalization)   (None, 120, 384)             1536      ['4_dwconv[0][0]']            \n                                                                                                  \n eca_3 (ECA)                 (None, 120, 384)             5         ['4_bn[0][0]']                \n                                                                                                  \n 4_project_conv (Dense)      (None, 120, 192)             73920     ['eca_3[0][0]']               \n                                                                                                  \n 4_drop (Dropout)            (None, 120, 192)             0         ['4_project_conv[0][0]']      \n                                                                                                  \n 4_add (Add)                 (None, 120, 192)             0         ['4_drop[0][0]',              \n                                                                     'add_1[0][0]']               \n                                                                                                  \n 5_expand_conv (Dense)       (None, 120, 384)             74112     ['4_add[0][0]']               \n                                                                                                  \n 5_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['5_expand_conv[0][0]']       \n                                                                                                  \n 5_bn (BatchNormalization)   (None, 120, 384)             1536      ['5_dwconv[0][0]']            \n                                                                                                  \n eca_4 (ECA)                 (None, 120, 384)             5         ['5_bn[0][0]']                \n                                                                                                  \n 5_project_conv (Dense)      (None, 120, 192)             73920     ['eca_4[0][0]']               \n                                                                                                  \n 5_drop (Dropout)            (None, 120, 192)             0         ['5_project_conv[0][0]']      \n                                                                                                  \n 5_add (Add)                 (None, 120, 192)             0         ['5_drop[0][0]',              \n                                                                     '4_add[0][0]']               \n                                                                                                  \n 6_expand_conv (Dense)       (None, 120, 384)             74112     ['5_add[0][0]']               \n                                                                                                  \n 6_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['6_expand_conv[0][0]']       \n                                                                                                  \n 6_bn (BatchNormalization)   (None, 120, 384)             1536      ['6_dwconv[0][0]']            \n                                                                                                  \n eca_5 (ECA)                 (None, 120, 384)             5         ['6_bn[0][0]']                \n                                                                                                  \n 6_project_conv (Dense)      (None, 120, 192)             73920     ['eca_5[0][0]']               \n                                                                                                  \n 6_drop (Dropout)            (None, 120, 192)             0         ['6_project_conv[0][0]']      \n                                                                                                  \n 6_add (Add)                 (None, 120, 192)             0         ['6_drop[0][0]',              \n                                                                     '5_add[0][0]']               \n                                                                                                  \n batch_normalization_2 (Bat  (None, 120, 192)             768       ['6_add[0][0]']               \n chNormalization)                                                                                 \n                                                                                                  \n multi_head_self_attention_  (None, 120, 192)             147456    ['batch_normalization_2[0][0]'\n 1 (MultiHeadSelfAttention)                                         ]                             \n                                                                                                  \n dropout_4 (Dropout)         (None, 120, 192)             0         ['multi_head_self_attention_1[\n                                                                    0][0]']                       \n                                                                                                  \n add_2 (Add)                 (None, 120, 192)             0         ['6_add[0][0]',               \n                                                                     'dropout_4[0][0]']           \n                                                                                                  \n batch_normalization_3 (Bat  (None, 120, 192)             768       ['add_2[0][0]']               \n chNormalization)                                                                                 \n                                                                                                  \n dense_6 (Dense)             (None, 120, 384)             73728     ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n dense_7 (Dense)             (None, 120, 192)             73728     ['dense_6[0][0]']             \n                                                                                                  \n dropout_5 (Dropout)         (None, 120, 192)             0         ['dense_7[0][0]']             \n                                                                                                  \n add_3 (Add)                 (None, 120, 192)             0         ['add_2[0][0]',               \n                                                                     'dropout_5[0][0]']           \n                                                                                                  \n 7_expand_conv (Dense)       (None, 120, 384)             74112     ['add_3[0][0]']               \n                                                                                                  \n 7_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['7_expand_conv[0][0]']       \n                                                                                                  \n 7_bn (BatchNormalization)   (None, 120, 384)             1536      ['7_dwconv[0][0]']            \n                                                                                                  \n eca_6 (ECA)                 (None, 120, 384)             5         ['7_bn[0][0]']                \n                                                                                                  \n 7_project_conv (Dense)      (None, 120, 192)             73920     ['eca_6[0][0]']               \n                                                                                                  \n 7_drop (Dropout)            (None, 120, 192)             0         ['7_project_conv[0][0]']      \n                                                                                                  \n 7_add (Add)                 (None, 120, 192)             0         ['7_drop[0][0]',              \n                                                                     'add_3[0][0]']               \n                                                                                                  \n 8_expand_conv (Dense)       (None, 120, 384)             74112     ['7_add[0][0]']               \n                                                                                                  \n 8_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['8_expand_conv[0][0]']       \n                                                                                                  \n 8_bn (BatchNormalization)   (None, 120, 384)             1536      ['8_dwconv[0][0]']            \n                                                                                                  \n eca_7 (ECA)                 (None, 120, 384)             5         ['8_bn[0][0]']                \n                                                                                                  \n 8_project_conv (Dense)      (None, 120, 192)             73920     ['eca_7[0][0]']               \n                                                                                                  \n 8_drop (Dropout)            (None, 120, 192)             0         ['8_project_conv[0][0]']      \n                                                                                                  \n 8_add (Add)                 (None, 120, 192)             0         ['8_drop[0][0]',              \n                                                                     '7_add[0][0]']               \n                                                                                                  \n 9_expand_conv (Dense)       (None, 120, 384)             74112     ['8_add[0][0]']               \n                                                                                                  \n 9_dwconv (CausalDWConv1D)   (None, 120, 384)             6528      ['9_expand_conv[0][0]']       \n                                                                                                  \n 9_bn (BatchNormalization)   (None, 120, 384)             1536      ['9_dwconv[0][0]']            \n                                                                                                  \n eca_8 (ECA)                 (None, 120, 384)             5         ['9_bn[0][0]']                \n                                                                                                  \n 9_project_conv (Dense)      (None, 120, 192)             73920     ['eca_8[0][0]']               \n                                                                                                  \n 9_drop (Dropout)            (None, 120, 192)             0         ['9_project_conv[0][0]']      \n                                                                                                  \n 9_add (Add)                 (None, 120, 192)             0         ['9_drop[0][0]',              \n                                                                     '8_add[0][0]']               \n                                                                                                  \n batch_normalization_4 (Bat  (None, 120, 192)             768       ['9_add[0][0]']               \n chNormalization)                                                                                 \n                                                                                                  \n multi_head_self_attention_  (None, 120, 192)             147456    ['batch_normalization_4[0][0]'\n 2 (MultiHeadSelfAttention)                                         ]                             \n                                                                                                  \n dropout_7 (Dropout)         (None, 120, 192)             0         ['multi_head_self_attention_2[\n                                                                    0][0]']                       \n                                                                                                  \n add_4 (Add)                 (None, 120, 192)             0         ['9_add[0][0]',               \n                                                                     'dropout_7[0][0]']           \n                                                                                                  \n batch_normalization_5 (Bat  (None, 120, 192)             768       ['add_4[0][0]']               \n chNormalization)                                                                                 \n                                                                                                  \n dense_10 (Dense)            (None, 120, 384)             73728     ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n dense_11 (Dense)            (None, 120, 192)             73728     ['dense_10[0][0]']            \n                                                                                                  \n dropout_8 (Dropout)         (None, 120, 192)             0         ['dense_11[0][0]']            \n                                                                                                  \n add_5 (Add)                 (None, 120, 192)             0         ['add_4[0][0]',               \n                                                                     'dropout_8[0][0]']           \n                                                                                                  \n top_conv (Dense)            (None, 120, 384)             74112     ['add_5[0][0]']               \n                                                                                                  \n global_average_pooling1d (  (None, 384)                  0         ['top_conv[0][0]']            \n GlobalAveragePooling1D)                                                                          \n                                                                                                  \n late_dropout (LateDropout)  (None, 384)                  1         ['global_average_pooling1d[0][\n                                                                    0]']                          \n                                                                                                  \n classifier (Dense)          (None, 531)                  204435    ['late_dropout[0][0]']        \n                                                                                                  \n==================================================================================================\nTotal params: 2605249 (9.94 MB)\nTrainable params: 2595648 (9.90 MB)\nNon-trainable params: 9601 (37.51 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"acc_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath='best_accuracy_weights.h5',\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True,\n)\n\nloss_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath='best_loss_weights.h5',\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True,\n)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    patience=50,\n    restore_best_weights=True\n)\n    \ntry:\n    hist = model.fit(\n        X_train, Y_train,\n        validation_data=(X_val, Y_val),\n        epochs=500,\n        batch_size=256,\n        callbacks=[acc_checkpoint, loss_checkpoint, early_stopping]\n    )\n    \nexcept KeyboardInterrupt:\n    model.load_weights('best_accuracy_weights.h5')\n    print(\"\\nManual interruption detected. Training stopped.\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T00:55:39.774389Z","iopub.execute_input":"2024-02-09T00:55:39.774755Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/500\n135/135 [==============================] - 151s 558ms/step - loss: 6.6981 - accuracy: 0.0027 - val_loss: 6.1398 - val_accuracy: 0.0089\nEpoch 2/500\n135/135 [==============================] - 73s 541ms/step - loss: 6.1646 - accuracy: 0.0073 - val_loss: 5.6268 - val_accuracy: 0.0240\nEpoch 3/500\n135/135 [==============================] - 74s 548ms/step - loss: 5.7299 - accuracy: 0.0169 - val_loss: 5.1251 - val_accuracy: 0.0453\nEpoch 4/500\n135/135 [==============================] - 74s 552ms/step - loss: 5.2902 - accuracy: 0.0325 - val_loss: 4.4794 - val_accuracy: 0.1032\nEpoch 5/500\n135/135 [==============================] - 75s 552ms/step - loss: 4.7709 - accuracy: 0.0683 - val_loss: 3.7320 - val_accuracy: 0.1901\nEpoch 6/500\n135/135 [==============================] - 75s 553ms/step - loss: 4.2532 - accuracy: 0.1169 - val_loss: 3.2895 - val_accuracy: 0.2716\nEpoch 7/500\n135/135 [==============================] - 75s 554ms/step - loss: 3.8008 - accuracy: 0.1734 - val_loss: 2.8446 - val_accuracy: 0.3568\nEpoch 8/500\n135/135 [==============================] - 75s 554ms/step - loss: 3.4499 - accuracy: 0.2246 - val_loss: 2.4912 - val_accuracy: 0.4175\nEpoch 9/500\n135/135 [==============================] - 75s 553ms/step - loss: 3.1381 - accuracy: 0.2805 - val_loss: 2.3142 - val_accuracy: 0.4532\nEpoch 10/500\n135/135 [==============================] - 75s 554ms/step - loss: 2.8964 - accuracy: 0.3173 - val_loss: 2.1423 - val_accuracy: 0.4708\nEpoch 11/500\n135/135 [==============================] - 75s 555ms/step - loss: 2.7194 - accuracy: 0.3566 - val_loss: 1.9023 - val_accuracy: 0.5323\nEpoch 12/500\n135/135 [==============================] - 75s 555ms/step - loss: 2.5618 - accuracy: 0.3856 - val_loss: 1.8055 - val_accuracy: 0.5580\nEpoch 13/500\n135/135 [==============================] - 75s 555ms/step - loss: 2.4366 - accuracy: 0.4101 - val_loss: 1.7157 - val_accuracy: 0.5722\nEpoch 14/500\n135/135 [==============================] - 75s 554ms/step - loss: 2.3077 - accuracy: 0.4338 - val_loss: 1.6889 - val_accuracy: 0.5750\nEpoch 15/500\n135/135 [==============================] - 75s 555ms/step - loss: 2.2206 - accuracy: 0.4528 - val_loss: 1.6080 - val_accuracy: 0.6006\nEpoch 16/500\n135/135 [==============================] - 75s 553ms/step - loss: 2.1267 - accuracy: 0.4723 - val_loss: 1.6210 - val_accuracy: 0.6033\nEpoch 17/500\n135/135 [==============================] - 75s 554ms/step - loss: 2.0637 - accuracy: 0.4870 - val_loss: 1.5667 - val_accuracy: 0.6154\nEpoch 18/500\n135/135 [==============================] - 75s 553ms/step - loss: 2.0024 - accuracy: 0.5034 - val_loss: 1.5356 - val_accuracy: 0.6224\nEpoch 19/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.9150 - accuracy: 0.5191 - val_loss: 1.5218 - val_accuracy: 0.6274\nEpoch 20/500\n135/135 [==============================] - 75s 552ms/step - loss: 1.8833 - accuracy: 0.5255 - val_loss: 1.5004 - val_accuracy: 0.6320\nEpoch 21/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.8506 - accuracy: 0.5390 - val_loss: 1.5099 - val_accuracy: 0.6262\nEpoch 22/500\n135/135 [==============================] - 75s 554ms/step - loss: 1.7516 - accuracy: 0.5563 - val_loss: 1.4924 - val_accuracy: 0.6450\nEpoch 23/500\n135/135 [==============================] - 75s 554ms/step - loss: 1.7660 - accuracy: 0.5568 - val_loss: 1.4247 - val_accuracy: 0.6595\nEpoch 24/500\n135/135 [==============================] - 75s 552ms/step - loss: 1.7183 - accuracy: 0.5667 - val_loss: 1.4583 - val_accuracy: 0.6620\nEpoch 25/500\n135/135 [==============================] - 75s 552ms/step - loss: 1.6932 - accuracy: 0.5754 - val_loss: 1.4552 - val_accuracy: 0.6581\nEpoch 26/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.6754 - accuracy: 0.5837 - val_loss: 1.3935 - val_accuracy: 0.6698\nEpoch 27/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.5971 - accuracy: 0.6002 - val_loss: 1.4296 - val_accuracy: 0.6613\nEpoch 28/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.5285 - accuracy: 0.6122 - val_loss: 1.4929 - val_accuracy: 0.6557\nEpoch 29/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.5489 - accuracy: 0.6096 - val_loss: 1.3795 - val_accuracy: 0.6708\nEpoch 30/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.4971 - accuracy: 0.6220 - val_loss: 1.3840 - val_accuracy: 0.6828\nEpoch 31/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.5065 - accuracy: 0.6252 - val_loss: 1.4294 - val_accuracy: 0.6846\nEpoch 32/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.5046 - accuracy: 0.6239 - val_loss: 1.4179 - val_accuracy: 0.6747\nEpoch 33/500\n135/135 [==============================] - 75s 554ms/step - loss: 1.4636 - accuracy: 0.6357 - val_loss: 1.4155 - val_accuracy: 0.6849\nEpoch 34/500\n135/135 [==============================] - 75s 552ms/step - loss: 1.4410 - accuracy: 0.6448 - val_loss: 1.4206 - val_accuracy: 0.6902\nEpoch 35/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.4553 - accuracy: 0.6410 - val_loss: 1.4876 - val_accuracy: 0.6859\nEpoch 36/500\n135/135 [==============================] - 74s 552ms/step - loss: 1.4195 - accuracy: 0.6477 - val_loss: 1.4626 - val_accuracy: 0.6856\nEpoch 37/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.3906 - accuracy: 0.6546 - val_loss: 1.5045 - val_accuracy: 0.6852\nEpoch 38/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.3498 - accuracy: 0.6624 - val_loss: 1.5224 - val_accuracy: 0.6797\nEpoch 39/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.3634 - accuracy: 0.6632 - val_loss: 1.4827 - val_accuracy: 0.6914\nEpoch 40/500\n135/135 [==============================] - 75s 552ms/step - loss: 1.3382 - accuracy: 0.6715 - val_loss: 1.4973 - val_accuracy: 0.6954\nEpoch 41/500\n135/135 [==============================] - 74s 552ms/step - loss: 1.3670 - accuracy: 0.6688 - val_loss: 1.5338 - val_accuracy: 0.6993\nEpoch 42/500\n135/135 [==============================] - 75s 552ms/step - loss: 1.3236 - accuracy: 0.6775 - val_loss: 1.4889 - val_accuracy: 0.6949\nEpoch 43/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.3120 - accuracy: 0.6801 - val_loss: 1.5400 - val_accuracy: 0.6926\nEpoch 44/500\n135/135 [==============================] - 74s 552ms/step - loss: 1.3022 - accuracy: 0.6862 - val_loss: 1.5021 - val_accuracy: 0.7027\nEpoch 45/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.3079 - accuracy: 0.6876 - val_loss: 1.5506 - val_accuracy: 0.6994\nEpoch 46/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.2371 - accuracy: 0.7027 - val_loss: 1.5328 - val_accuracy: 0.7046\nEpoch 47/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.2297 - accuracy: 0.7025 - val_loss: 1.5277 - val_accuracy: 0.7037\nEpoch 48/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.2598 - accuracy: 0.7013 - val_loss: 1.6060 - val_accuracy: 0.6961\nEpoch 49/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.2920 - accuracy: 0.6996 - val_loss: 1.6517 - val_accuracy: 0.6983\nEpoch 50/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.2069 - accuracy: 0.7112 - val_loss: 1.6603 - val_accuracy: 0.6962\nEpoch 51/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.2603 - accuracy: 0.7068 - val_loss: 1.6939 - val_accuracy: 0.7008\nEpoch 52/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.2400 - accuracy: 0.7112 - val_loss: 1.7627 - val_accuracy: 0.6945\nEpoch 53/500\n135/135 [==============================] - 75s 553ms/step - loss: 1.2461 - accuracy: 0.7135 - val_loss: 1.6745 - val_accuracy: 0.7060\nEpoch 54/500\n135/135 [==============================] - 74s 552ms/step - loss: 1.2057 - accuracy: 0.7203 - val_loss: 1.7170 - val_accuracy: 0.7094\nEpoch 55/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.2392 - accuracy: 0.7204 - val_loss: 1.7882 - val_accuracy: 0.7050\nEpoch 56/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.2438 - accuracy: 0.7200 - val_loss: 1.7043 - val_accuracy: 0.7090\nEpoch 57/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.2046 - accuracy: 0.7251 - val_loss: 1.7277 - val_accuracy: 0.7027\nEpoch 58/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.1918 - accuracy: 0.7297 - val_loss: 1.7678 - val_accuracy: 0.6959\nEpoch 59/500\n135/135 [==============================] - 74s 552ms/step - loss: 1.1948 - accuracy: 0.7331 - val_loss: 1.7470 - val_accuracy: 0.7153\nEpoch 60/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.1696 - accuracy: 0.7329 - val_loss: 1.7460 - val_accuracy: 0.7072\nEpoch 61/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.1366 - accuracy: 0.7447 - val_loss: 1.8163 - val_accuracy: 0.7082\nEpoch 62/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.1352 - accuracy: 0.7464 - val_loss: 1.8996 - val_accuracy: 0.7075\nEpoch 63/500\n135/135 [==============================] - 75s 552ms/step - loss: 1.1301 - accuracy: 0.7484 - val_loss: 1.8562 - val_accuracy: 0.7061\nEpoch 64/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.1532 - accuracy: 0.7485 - val_loss: 1.9379 - val_accuracy: 0.7034\nEpoch 65/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.1620 - accuracy: 0.7461 - val_loss: 1.9344 - val_accuracy: 0.7009\nEpoch 66/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.2106 - accuracy: 0.7425 - val_loss: 1.9345 - val_accuracy: 0.7104\nEpoch 67/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.1841 - accuracy: 0.7506 - val_loss: 1.9129 - val_accuracy: 0.7133\nEpoch 68/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.1828 - accuracy: 0.7511 - val_loss: 2.0000 - val_accuracy: 0.7062\nEpoch 69/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.2342 - accuracy: 0.7457 - val_loss: 2.0721 - val_accuracy: 0.7090\nEpoch 70/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.2921 - accuracy: 0.7390 - val_loss: 2.1014 - val_accuracy: 0.7076\nEpoch 71/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.2253 - accuracy: 0.7500 - val_loss: 2.0299 - val_accuracy: 0.7147\nEpoch 72/500\n135/135 [==============================] - 74s 552ms/step - loss: 1.1812 - accuracy: 0.7567 - val_loss: 2.0611 - val_accuracy: 0.7145\nEpoch 73/500\n135/135 [==============================] - 75s 552ms/step - loss: 1.1315 - accuracy: 0.7659 - val_loss: 2.0637 - val_accuracy: 0.7200\nEpoch 74/500\n135/135 [==============================] - 74s 552ms/step - loss: 1.0982 - accuracy: 0.7733 - val_loss: 2.0399 - val_accuracy: 0.7219\nEpoch 75/500\n135/135 [==============================] - 74s 551ms/step - loss: 1.1101 - accuracy: 0.7727 - val_loss: 2.2701 - val_accuracy: 0.7082\nEpoch 76/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.1114 - accuracy: 0.7728 - val_loss: 2.2462 - val_accuracy: 0.7004\nEpoch 77/500\n135/135 [==============================] - 74s 550ms/step - loss: 1.1174 - accuracy: 0.7738 - val_loss: 2.3309 - val_accuracy: 0.7072\nEpoch 78/500\n 24/135 [====>.........................] - ETA: 58s - loss: 1.1859 - accuracy: 0.7733","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights('best_accuracy_weights.h5')\n# del X_train, Y_train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:44:13.164393Z","iopub.execute_input":"2024-02-09T02:44:13.164966Z","iopub.status.idle":"2024-02-09T02:44:14.446459Z","shell.execute_reply.started":"2024-02-09T02:44:13.164925Z","shell.execute_reply":"2024-02-09T02:44:14.44555Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"2694"},"metadata":{}}]},{"cell_type":"code","source":"model.evaluate(X_val, Y_val)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:44:16.038243Z","iopub.execute_input":"2024-02-09T02:44:16.039094Z","iopub.status.idle":"2024-02-09T02:44:23.002221Z","shell.execute_reply.started":"2024-02-09T02:44:16.039061Z","shell.execute_reply":"2024-02-09T02:44:23.00125Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"225/225 [==============================] - 6s 27ms/step - loss: 2.0399 - accuracy: 0.7219\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"[2.039933919906616, 0.721858024597168]"},"metadata":{}}]},{"cell_type":"code","source":"model.evaluate(X_test, Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:44:23.872583Z","iopub.execute_input":"2024-02-09T02:44:23.875315Z","iopub.status.idle":"2024-02-09T02:44:26.693497Z","shell.execute_reply.started":"2024-02-09T02:44:23.875269Z","shell.execute_reply":"2024-02-09T02:44:26.692515Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"70/70 [==============================] - 2s 27ms/step - loss: 1.3516 - accuracy: 0.7954\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"[1.3515636920928955, 0.7953529953956604]"},"metadata":{}}]},{"cell_type":"code","source":"# del X_val, Y_val\n# gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Model_Visualization\">\n    \n# **Model Visualization**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"code","source":"train_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\n\n# Plotting loss\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_loss,  label='Training loss')\nplt.plot(val_loss, label='Validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel(f'Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plotting accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_acc, label='Training accuracy')\nplt.plot(val_acc, label='Validation accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel(f'Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = '2-9-acc'\nmodel_filepath = '/kaggle/working/Models'\nos.makedirs(model_filepath, exist_ok=True)\n\nmodel.save(model_filepath + f'/{name}.h5')\nmodel.save(model_filepath + f'/{name}')\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_filepath + f'/{name}')\nconverter.target_spec.supported_ops = [\n  tf.lite.OpsSet.TFLITE_BUILTINS,\n  tf.lite.OpsSet.SELECT_TF_OPS\n]\ntflite_model = converter.convert()\nwith open(model_filepath + f'/{name}.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nshutil.rmtree(model_filepath + f'/{name}')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T23:20:21.034649Z","iopub.execute_input":"2024-02-08T23:20:21.035562Z","iopub.status.idle":"2024-02-08T23:20:38.932472Z","shell.execute_reply.started":"2024-02-08T23:20:21.035523Z","shell.execute_reply":"2024-02-08T23:20:38.931456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nY_pred_probabilities = model.predict(X_test)\nY_pred = np.argmax(Y_pred_probabilities, axis=1)\nconf_matrix = confusion_matrix(Y_test, Y_pred)\nconf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n\nplt.figure(figsize=(24, 20))\nsns.heatmap(conf_matrix, cmap='Blues', annot=False, square=True)\n\nplt.title('Confusion Matrix for Test Data')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T23:20:38.934349Z","iopub.execute_input":"2024-02-08T23:20:38.934726Z","iopub.status.idle":"2024-02-08T23:20:45.805987Z","shell.execute_reply.started":"2024-02-08T23:20:38.934697Z","shell.execute_reply":"2024-02-08T23:20:45.804883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del X_test, Y_test\n# gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Extras\">\n    \n# **Extras**\n    \n<div align=\"right\">\n    <b><a href=\"#Introduction\">Home</a></b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"**<h3>Refining evaluation graphs**","metadata":{}},{"cell_type":"code","source":"interval = 10\n\n# Get the best loss and accuracy within each interval\ntrain_loss = [np.min(hist.history['loss'][i:i+interval]) for i in range(0, len(hist.history['loss']), interval)]\nval_loss = [np.min(hist.history['val_loss'][i:i+interval]) for i in range(0, len(hist.history['val_loss']), interval)]\ntrain_acc = [np.max(hist.history['accuracy'][i:i+interval]) for i in range(0, len(hist.history['accuracy']), interval)]\nval_acc = [np.max(hist.history['val_accuracy'][i:i+interval]) for i in range(0, len(hist.history['val_accuracy']), interval)]\nx_axis_values = [i*interval for i in range(len(train_loss))]\n\n# Plotting loss\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(x_axis_values, train_loss, label='Training loss')\nplt.plot(x_axis_values, val_loss, label='Validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plotting accuracy\nplt.subplot(1, 2, 2)\nplt.plot(x_axis_values, train_acc, label='Training accuracy')\nplt.plot(x_axis_values, val_acc, label='Validation accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T02:10:50.775299Z","iopub.execute_input":"2024-02-08T02:10:50.776033Z","iopub.status.idle":"2024-02-08T02:10:51.266116Z","shell.execute_reply.started":"2024-02-08T02:10:50.776Z","shell.execute_reply":"2024-02-08T02:10:51.265115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<h3>Testing best loss model**","metadata":{}},{"cell_type":"code","source":"model.load_weights('best_loss_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T23:21:33.734364Z","iopub.execute_input":"2024-02-08T23:21:33.735553Z","iopub.status.idle":"2024-02-08T23:21:33.842981Z","shell.execute_reply.started":"2024-02-08T23:21:33.735512Z","shell.execute_reply":"2024-02-08T23:21:33.841847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_val, Y_val)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T23:21:33.992092Z","iopub.execute_input":"2024-02-08T23:21:33.992498Z","iopub.status.idle":"2024-02-08T23:21:40.74284Z","shell.execute_reply.started":"2024-02-08T23:21:33.992466Z","shell.execute_reply":"2024-02-08T23:21:40.74152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test, Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T23:21:40.745251Z","iopub.execute_input":"2024-02-08T23:21:40.746031Z","iopub.status.idle":"2024-02-08T23:21:42.714413Z","shell.execute_reply.started":"2024-02-08T23:21:40.745985Z","shell.execute_reply":"2024-02-08T23:21:42.713249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = '2-9-loss'\nmodel_filepath = '/kaggle/working/Models'\nos.makedirs(model_filepath, exist_ok=True)\n\nmodel.save(model_filepath + f'/{name}.h5')\nmodel.save_weights(model_filepath + f'/{name}.h5')\n\nmodel.save(model_filepath + f'/{name}')\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_filepath + f'/{name}')\nconverter.target_spec.supported_ops = [\n  tf.lite.OpsSet.TFLITE_BUILTINS,\n  tf.lite.OpsSet.SELECT_TF_OPS\n]\ntflite_model = converter.convert()\nwith open(model_filepath + f'/{name}.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nshutil.rmtree(model_filepath + f'/{name}')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T23:21:44.704271Z","iopub.execute_input":"2024-02-08T23:21:44.704689Z","iopub.status.idle":"2024-02-08T23:22:02.67935Z","shell.execute_reply.started":"2024-02-08T23:21:44.704659Z","shell.execute_reply":"2024-02-08T23:22:02.678435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nY_pred_probabilities = model.predict(X_test)\nY_pred = np.argmax(Y_pred_probabilities, axis=1)\nconf_matrix = confusion_matrix(Y_test, Y_pred)\nconf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n\nplt.figure(figsize=(24, 20))\nsns.heatmap(conf_matrix, cmap='Blues', annot=False, square=True)\n\nplt.title('Confusion Matrix for Test Data')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T23:22:02.682835Z","iopub.execute_input":"2024-02-08T23:22:02.683772Z","iopub.status.idle":"2024-02-08T23:22:07.421455Z","shell.execute_reply.started":"2024-02-08T23:22:02.683726Z","shell.execute_reply":"2024-02-08T23:22:07.420291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<h3>Search for any video by label**","metadata":{}},{"cell_type":"code","source":"label = 'welcome'\n\ndata = pd.read_csv('/kaggle/input/asl-citizen-encoded/Data/data.csv')\nvideo_names = data.loc[(data['clean label'] == label) & (data['split'] == 'test'), 'video'].tolist()\nvideo_names","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:16:49.137684Z","iopub.execute_input":"2024-02-08T05:16:49.138177Z","iopub.status.idle":"2024-02-08T05:16:49.275883Z","shell.execute_reply.started":"2024-02-08T05:16:49.138138Z","shell.execute_reply":"2024-02-08T05:16:49.274795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_name = video_names[4]\nsource_path = '/kaggle/input/asl-citizen/ASL_Citizen/videos/' + video_name\ndestination_path = '/kaggle/working/'\n\nshutil.copy(source_path, destination_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:16:49.974595Z","iopub.execute_input":"2024-02-08T05:16:49.975071Z","iopub.status.idle":"2024-02-08T05:16:49.985394Z","shell.execute_reply.started":"2024-02-08T05:16:49.975035Z","shell.execute_reply":"2024-02-08T05:16:49.984085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.remove(destination_path + video_name)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T05:16:45.86838Z","iopub.execute_input":"2024-02-08T05:16:45.868752Z","iopub.status.idle":"2024-02-08T05:16:45.873372Z","shell.execute_reply.started":"2024-02-08T05:16:45.868722Z","shell.execute_reply":"2024-02-08T05:16:45.87223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**<h3>Evaluate TFLite model**","metadata":{}},{"cell_type":"code","source":"model_path = '/kaggle/input/asl-citizen-output/Models/2-8(1)-acc.tflite'\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\noutput_shape = output_details[0]['shape']\nprint(f'Input Shape: {input_shape}, Output Shape: {output_shape}')\n\ncorrect_gloss = 0\ncorrect_label = 0\nfor i in tqdm(range(len(Y_test)), ncols=100):\n    input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    output = interpreter.get_tensor(output_details[0]['index'])\n    prediction = output.argmax()\n    if index_label_mapping[prediction] == index_label_mapping[Y_test[i]]:\n        correct_label += 1\n        if prediction == Y_test[i]:\n            correct_gloss += 1\ngloss_accuracy = correct_gloss / len(Y_test)\nlabel_accuracy = correct_label / len(Y_test)\nprint(f'Gloss Accuracy: {gloss_accuracy:.4f}')\nprint(f'Label Accuracy: {label_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:04:20.967849Z","iopub.execute_input":"2024-02-09T14:04:20.968429Z","iopub.status.idle":"2024-02-09T14:04:43.388701Z","shell.execute_reply.started":"2024-02-09T14:04:20.968391Z","shell.execute_reply":"2024-02-09T14:04:43.387968Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Input Shape: [  1 120  55   3], Output Shape: [  1 590]\n","output_type":"stream"},{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nWARNING: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#97 is a dynamic-sized tensor).\n100%|██████████████████████████████████████████████████████████| 2238/2238 [00:22<00:00, 100.64it/s]","output_type":"stream"},{"name":"stdout","text":"Gloss Accuracy: 0.7775\nLabel Accuracy: 0.7971\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**<h3>Neuron confidence range**","metadata":{}},{"cell_type":"code","source":"Y_pred = []\n\nfor i in tqdm(range(len(Y_val))):\n    input_data = np.expand_dims(X_val[i], axis=0).astype(np.float32)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    Y_pred.append(output_data[0])\n\nY_pred = np.array(Y_pred)\nY_pred.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:05:04.447427Z","iopub.execute_input":"2024-02-09T14:05:04.44789Z","iopub.status.idle":"2024-02-09T14:06:15.870691Z","shell.execute_reply.started":"2024-02-09T14:05:04.447859Z","shell.execute_reply":"2024-02-09T14:06:15.869499Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"100%|██████████| 7169/7169 [01:11<00:00, 100.42it/s]\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"(7169, 590)"},"metadata":{}}]},{"cell_type":"code","source":"class_idxs = np.argmax(Y_pred, axis=1)\nclass_idxs.shape, np.unique(class_idxs).shape","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:06:22.182748Z","iopub.execute_input":"2024-02-09T14:06:22.183161Z","iopub.status.idle":"2024-02-09T14:06:22.192739Z","shell.execute_reply.started":"2024-02-09T14:06:22.18313Z","shell.execute_reply":"2024-02-09T14:06:22.191294Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"((7169,), (590,))"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate average prediction for each class\navg_positive = np.array([np.mean(Y_pred[class_idxs == cls] + 1e-6, axis=0)[cls] for cls in range(len(glosses))])\navg_negative = np.array([np.mean(Y_pred[class_idxs != cls] + 1e-6, axis=0)[cls] for cls in range(len(glosses))])\n\n# Calculate standard deviation for each class\nstd_positive = np.array([np.std(Y_pred[class_idxs == cls] + 1e-6, axis=0)[cls] for cls in range(len(glosses))])\nstd_negative = np.array([np.std(Y_pred[class_idxs != cls] + 1e-6, axis=0)[cls] for cls in range(len(glosses))])\n\n# Calculate estimated range for last layer neurons\nrange_positive_lower = avg_positive - 2 * std_positive\nrange_positive_upper = avg_positive + 2 * std_positive\nrange_positive = np.stack((range_positive_lower, avg_positive, range_positive_upper), axis=1)\n\nrange_negative_lower = avg_negative - 2 * std_negative\nrange_negative_upper = avg_negative + 2 * std_negative\nrange_negative = np.stack((range_negative_lower, avg_negative, range_negative_upper), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:06:44.731627Z","iopub.execute_input":"2024-02-09T14:06:44.732118Z","iopub.status.idle":"2024-02-09T14:06:54.086243Z","shell.execute_reply.started":"2024-02-09T14:06:44.732086Z","shell.execute_reply":"2024-02-09T14:06:54.085193Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"f'Shape: {range_positive.shape}, Examples: {range_positive[5]}, {range_positive[9]}, {range_positive[15]}'","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:06:54.087723Z","iopub.execute_input":"2024-02-09T14:06:54.088036Z","iopub.status.idle":"2024-02-09T14:06:54.094791Z","shell.execute_reply.started":"2024-02-09T14:06:54.087989Z","shell.execute_reply":"2024-02-09T14:06:54.093428Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'Shape: (590, 3), Examples: [23.612423 37.193367 50.77431 ], [17.09092 41.1387  65.18648], [27.20055  51.646294 76.09204 ]'"},"metadata":{}}]},{"cell_type":"code","source":"range_positive[80], range_negative[80]","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:07:59.530074Z","iopub.execute_input":"2024-02-09T14:07:59.530487Z","iopub.status.idle":"2024-02-09T14:07:59.536862Z","shell.execute_reply.started":"2024-02-09T14:07:59.530461Z","shell.execute_reply":"2024-02-09T14:07:59.536039Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(array([32.624954, 55.20729 , 77.78963 ], dtype=float32),\n array([-19.294615 ,  -1.4654182,  16.36378  ], dtype=float32))"},"metadata":{}}]},{"cell_type":"code","source":"np.save('range_positive.npy', range_positive)\nnp.save('range_negative.npy', range_negative)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T14:08:32.317286Z","iopub.execute_input":"2024-02-09T14:08:32.318148Z","iopub.status.idle":"2024-02-09T14:08:32.326075Z","shell.execute_reply.started":"2024-02-09T14:08:32.3181Z","shell.execute_reply":"2024-02-09T14:08:32.324538Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def calculate_certainty(pred, pos_range, neg_range):\n    z_score_true = abs(pred - pos_range[1]) / (pos_range[2] - pos_range[0])\n    z_score_false = abs(pred - neg_range[1]) / (neg_range[2] - neg_range[0])\n    return z_score_false / (z_score_true + z_score_false)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T15:25:56.222117Z","iopub.execute_input":"2024-02-09T15:25:56.222538Z","iopub.status.idle":"2024-02-09T15:25:56.228212Z","shell.execute_reply.started":"2024-02-09T15:25:56.22251Z","shell.execute_reply":"2024-02-09T15:25:56.227145Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"print(f'{calculate_certainty(50, range_positive[80], range_negative[80]) * 100:.2f} %')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T15:30:03.8766Z","iopub.execute_input":"2024-02-09T15:30:03.877186Z","iopub.status.idle":"2024-02-09T15:30:03.884374Z","shell.execute_reply.started":"2024-02-09T15:30:03.877146Z","shell.execute_reply":"2024-02-09T15:30:03.882948Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"92.60 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---","metadata":{}}]}